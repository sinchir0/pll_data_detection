{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "- 推論時のtokenizeと学習時のtokenizeのやり方を合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:46:44.133408Z",
     "iopub.status.busy": "2024-02-17T10:46:44.133241Z",
     "iopub.status.idle": "2024-02-17T10:46:44.139845Z",
     "shell.execute_reply": "2024-02-17T10:46:44.139426Z"
    }
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"e04-match-tokenize\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "DATA_PATH = \"pll_data_detection/data\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME}\"\n",
    "LOG_PATH = f\"pll_data_detection/log/{EXP_NAME}\"\n",
    "MODEL_OUTPUT_PATH = f\"pll_data_detection/trained_models/{EXP_NAME}\"\n",
    "DEBUG = False\n",
    "UPLOAD_DATA = True\n",
    "TRAINING_MAX_LENGTH = 1024  # NOTE: ほとんどOなのに、後半のtokenに正解があると、truncationで落ちてしまって勿体無い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:46:44.141681Z",
     "iopub.status.busy": "2024-02-17T10:46:44.141527Z",
     "iopub.status.idle": "2024-02-17T10:47:08.636948Z",
     "shell.execute_reply": "2024-02-17T10:47:08.636369Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install polars\n",
    "%pip install transformers==4.37.2\n",
    "%pip install datasets==2.16.1\n",
    "%pip install evaluate==0.4.1\n",
    "%pip install seqeval==1.2.2\n",
    "%pip install accelerate\n",
    "%pip install python-dotenv\n",
    "%pip install kaggle\n",
    "%pip iinstall wandb==0.16.3\n",
    "\n",
    "# formatter\n",
    "%pip install black isort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:08.640245Z",
     "iopub.status.busy": "2024-02-17T10:47:08.640040Z",
     "iopub.status.idle": "2024-02-17T10:47:12.452788Z",
     "shell.execute_reply": "2024-02-17T10:47:12.452109Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TokenClassificationPipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:12.456281Z",
     "iopub.status.busy": "2024-02-17T10:47:12.456076Z",
     "iopub.status.idle": "2024-02-17T10:47:12.458813Z",
     "shell.execute_reply": "2024-02-17T10:47:12.458155Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "assert transformers.__version__ == \"4.37.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:12.461382Z",
     "iopub.status.busy": "2024-02-17T10:47:12.461191Z",
     "iopub.status.idle": "2024-02-17T10:47:12.464522Z",
     "shell.execute_reply": "2024-02-17T10:47:12.464036Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "assert datasets.__version__ == \"2.16.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:12.466656Z",
     "iopub.status.busy": "2024-02-17T10:47:12.466503Z",
     "iopub.status.idle": "2024-02-17T10:47:12.468811Z",
     "shell.execute_reply": "2024-02-17T10:47:12.468304Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "assert evaluate.__version__ == \"0.4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:12.471018Z",
     "iopub.status.busy": "2024-02-17T10:47:12.470867Z",
     "iopub.status.idle": "2024-02-17T10:47:14.075002Z",
     "shell.execute_reply": "2024-02-17T10:47:14.074277Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "if not DEBUG:\n",
    "    load_dotenv(\"pll_data_detection/.env\")\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=\"pll\", name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:14.091880Z",
     "iopub.status.busy": "2024-02-17T10:47:14.091653Z",
     "iopub.status.idle": "2024-02-17T10:47:14.691813Z",
     "shell.execute_reply": "2024-02-17T10:47:14.691036Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:14.694967Z",
     "iopub.status.busy": "2024-02-17T10:47:14.694755Z",
     "iopub.status.idle": "2024-02-17T10:47:15.571623Z",
     "shell.execute_reply": "2024-02-17T10:47:15.570904Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:15.574643Z",
     "iopub.status.busy": "2024-02-17T10:47:15.574410Z",
     "iopub.status.idle": "2024-02-17T10:47:17.098020Z",
     "shell.execute_reply": "2024-02-17T10:47:17.097414Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>full_text</th><th>tokens</th><th>trailing_whitespace</th><th>labels</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[bool]</td><td>list[str]</td></tr></thead><tbody><tr><td>7</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>10</td><td>&quot;Diego Estrada\n",
       "…</td><td>[&quot;Diego&quot;, &quot;Estrada&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;B-NAME_STUDENT&quot;, &quot;I-NAME_STUDENT&quot;, … &quot;O&quot;]</td></tr><tr><td>16</td><td>&quot;Reporting proc…</td><td>[&quot;Reporting&quot;, &quot;process&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>20</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>56</td><td>&quot;Assignment:  V…</td><td>[&quot;Assignment&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────┬─────────────────────┬─────────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ document ┆ full_text           ┆ tokens              ┆ trailing_whitespace ┆ labels              │\n",
       "│ ---      ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---                 │\n",
       "│ i64      ┆ str                 ┆ list[str]           ┆ list[bool]          ┆ list[str]           │\n",
       "╞══════════╪═════════════════════╪═════════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 7        ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ innovation r…       ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 10       ┆ Diego Estrada       ┆ [\"Diego\",           ┆ [true, false, …     ┆ [\"B-NAME_STUDENT\",  │\n",
       "│          ┆                     ┆ \"Estrada\", … \"      ┆ false]              ┆ \"I-NAME_STUDE…      │\n",
       "│          ┆ Design Thinking A…  ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 16       ┆ Reporting process   ┆ [\"Reporting\",       ┆ [true, false, …     ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆ \"process\", … \"      ┆ false]              ┆                     │\n",
       "│          ┆ by Gilberto G…      ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 20       ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ Innovation          ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆ …                   ┆ \"]                  ┆                     ┆                     │\n",
       "│ 56       ┆ Assignment:  Visual ┆ [\"Assignment\", \":\", ┆ [false, false, …    ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ ization Refle…      ┆ … \"                 ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "└──────────┴─────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ確認用\n",
    "train = pl.read_json(f\"{DATA_PATH}/train.json\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:17.100648Z",
     "iopub.status.busy": "2024-02-17T10:47:17.100466Z",
     "iopub.status.idle": "2024-02-17T10:47:18.589842Z",
     "shell.execute_reply": "2024-02-17T10:47:18.589210Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6_807, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>full_text</th><th>tokens</th><th>trailing_whitespace</th><th>labels</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[bool]</td><td>list[str]</td></tr></thead><tbody><tr><td>7</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>10</td><td>&quot;Diego Estrada\n",
       "…</td><td>[&quot;Diego&quot;, &quot;Estrada&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;B-NAME_STUDENT&quot;, &quot;I-NAME_STUDENT&quot;, … &quot;O&quot;]</td></tr><tr><td>16</td><td>&quot;Reporting proc…</td><td>[&quot;Reporting&quot;, &quot;process&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>20</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>56</td><td>&quot;Assignment:  V…</td><td>[&quot;Assignment&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>86</td><td>&quot;Cheese Startup…</td><td>[&quot;Cheese&quot;, &quot;Startup&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>93</td><td>&quot;Silvia Villalo…</td><td>[&quot;Silvia&quot;, &quot;Villalobos&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;B-NAME_STUDENT&quot;, &quot;I-NAME_STUDENT&quot;, … &quot;O&quot;]</td></tr><tr><td>104</td><td>&quot;Storytelling  …</td><td>[&quot;Storytelling&quot;, &quot; &quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>112</td><td>&quot;Reflection – L…</td><td>[&quot;Reflection&quot;, &quot;–&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>123</td><td>&quot;Gandhi Institu…</td><td>[&quot;Gandhi&quot;, &quot;Institute&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>136</td><td>&quot;Dear Corrector…</td><td>[&quot;Dear&quot;, &quot;Corrector&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>166</td><td>&quot;Pepa Medrano\n",
       "\n",
       "…</td><td>[&quot;Pepa&quot;, &quot;Medrano&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;B-NAME_STUDENT&quot;, &quot;I-NAME_STUDENT&quot;, … &quot;O&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>22663</td><td>&quot;Reﬂection Stor…</td><td>[&quot;Reﬂection&quot;, &quot;Storytelling&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22664</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22668</td><td>&quot;Visualization …</td><td>[&quot;Visualization&quot;, &quot;Tool&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22672</td><td>&quot;Challenge:    …</td><td>[&quot;Challenge&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22674</td><td>&quot;Reflection – V…</td><td>[&quot;Reflection&quot;, &quot;–&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22675</td><td>&quot;Example Reflec…</td><td>[&quot;Example&quot;, &quot;Reflection&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22677</td><td>&quot;Mind Mapping T…</td><td>[&quot;Mind&quot;, &quot;Mapping&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22678</td><td>&quot;EXAMPLE – JOUR…</td><td>[&quot;EXAMPLE&quot;, &quot;–&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22679</td><td>&quot;Why Mind Mappi…</td><td>[&quot;Why&quot;, &quot;Mind&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22681</td><td>&quot;Challenge\n",
       "\n",
       "So,…</td><td>[&quot;Challenge&quot;, &quot;\n",
       "\n",
       "&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22684</td><td>&quot;Brainstorming\n",
       "…</td><td>[&quot;Brainstorming&quot;, &quot;\n",
       "\n",
       "&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>22687</td><td>&quot;Mind Mapping\n",
       "\n",
       "…</td><td>[&quot;Mind&quot;, &quot;Mapping&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6_807, 5)\n",
       "┌──────────┬─────────────────────┬─────────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ document ┆ full_text           ┆ tokens              ┆ trailing_whitespace ┆ labels              │\n",
       "│ ---      ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---                 │\n",
       "│ i64      ┆ str                 ┆ list[str]           ┆ list[bool]          ┆ list[str]           │\n",
       "╞══════════╪═════════════════════╪═════════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 7        ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ innovation r…       ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 10       ┆ Diego Estrada       ┆ [\"Diego\",           ┆ [true, false, …     ┆ [\"B-NAME_STUDENT\",  │\n",
       "│          ┆                     ┆ \"Estrada\", … \"      ┆ false]              ┆ \"I-NAME_STUDE…      │\n",
       "│          ┆ Design Thinking A…  ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 16       ┆ Reporting process   ┆ [\"Reporting\",       ┆ [true, false, …     ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆ \"process\", … \"      ┆ false]              ┆                     │\n",
       "│          ┆ by Gilberto G…      ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 20       ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ Innovation          ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆ …                   ┆ \"]                  ┆                     ┆                     │\n",
       "│ 56       ┆ Assignment:  Visual ┆ [\"Assignment\", \":\", ┆ [false, false, …    ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ ization Refle…      ┆ … \"                 ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ …        ┆ …                   ┆ …                   ┆ …                   ┆ …                   │\n",
       "│ 22678    ┆ EXAMPLE – JOURNEY   ┆ [\"EXAMPLE\", \"–\", …  ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ MAP                 ┆ \"                   ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆ THE CHALL…          ┆ \"]                  ┆                     ┆                     │\n",
       "│ 22679    ┆ Why Mind Mapping?   ┆ [\"Why\", \"Mind\", … \" ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆                     ┆ false]              ┆                     │\n",
       "│          ┆ Mind maps are…      ┆ \"]                  ┆                     ┆                     │\n",
       "│ 22681    ┆ Challenge           ┆ [\"Challenge\", \"     ┆ [false, false, …    ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆                     ┆ false]              ┆                     │\n",
       "│          ┆ So, a few months    ┆ \", … \"              ┆                     ┆                     │\n",
       "│          ┆ back…               ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 22684    ┆ Brainstorming       ┆ [\"Brainstorming\", \" ┆ [false, false, …    ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆                     ┆ false]              ┆                     │\n",
       "│          ┆ Challenge & Selec…  ┆ \", … \"              ┆                     ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 22687    ┆ Mind Mapping        ┆ [\"Mind\", \"Mapping\", ┆ [true, false, …     ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆ … \"                 ┆ false]              ┆                     │\n",
       "│          ┆ Challenge           ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│          ┆ My cons…            ┆                     ┆                     ┆                     │\n",
       "└──────────┴─────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ確認用\n",
    "test = pl.read_json(f\"{DATA_PATH}/train.json\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:18.592339Z",
     "iopub.status.busy": "2024-02-17T10:47:18.592165Z",
     "iopub.status.idle": "2024-02-17T10:47:18.777297Z",
     "shell.execute_reply": "2024-02-17T10:47:18.776764Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"json\", data_files={\"train\": f\"{DATA_PATH}/train.json\"}, split=\"train\"\n",
    ").rename_column(\"labels\", \"provided_labels\")\n",
    "\n",
    "test_dataset = load_dataset(\n",
    "    \"json\", data_files={\"test\": f\"{DATA_PATH}/test.json\"}, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:18.780161Z",
     "iopub.status.busy": "2024-02-17T10:47:18.779982Z",
     "iopub.status.idle": "2024-02-17T10:47:18.782829Z",
     "shell.execute_reply": "2024-02-17T10:47:18.782295Z"
    }
   },
   "outputs": [],
   "source": [
    "# debug\n",
    "if DEBUG:\n",
    "    train_dataset = train_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:18.784883Z",
     "iopub.status.busy": "2024-02-17T10:47:18.784725Z",
     "iopub.status.idle": "2024-02-17T10:47:18.788002Z",
     "shell.execute_reply": "2024-02-17T10:47:18.787514Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['provided_labels', 'document', 'trailing_whitespace', 'tokens', 'full_text'],\n",
       "    num_rows: 6807\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:18.790239Z",
     "iopub.status.busy": "2024-02-17T10:47:18.790078Z",
     "iopub.status.idle": "2024-02-17T10:47:18.793226Z",
     "shell.execute_reply": "2024-02-17T10:47:18.792738Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'full_text', 'trailing_whitespace', 'document'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:18.795334Z",
     "iopub.status.busy": "2024-02-17T10:47:18.795176Z",
     "iopub.status.idle": "2024-02-17T10:47:19.582924Z",
     "shell.execute_reply": "2024-02-17T10:47:19.582278Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.585579Z",
     "iopub.status.busy": "2024-02-17T10:47:19.585396Z",
     "iopub.status.idle": "2024-02-17T10:47:19.600482Z",
     "shell.execute_reply": "2024-02-17T10:47:19.599935Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '▁Design',\n",
       " '▁Thinking',\n",
       " '▁for',\n",
       " '▁innovation',\n",
       " '▁reflex',\n",
       " 'ion',\n",
       " '▁-',\n",
       " '▁Avril',\n",
       " '▁2021',\n",
       " '▁-',\n",
       " '▁Nathalie',\n",
       " '▁S',\n",
       " 'ylla',\n",
       " '▁Challenge',\n",
       " '▁&',\n",
       " '▁selection',\n",
       " '▁The',\n",
       " '▁tool',\n",
       " '▁I',\n",
       " '▁use',\n",
       " '▁to',\n",
       " '▁help',\n",
       " '▁all',\n",
       " '▁stakeholders',\n",
       " '▁finding',\n",
       " '▁their',\n",
       " '▁way',\n",
       " '▁through',\n",
       " '▁the',\n",
       " '▁complexity',\n",
       " '▁of',\n",
       " '▁a',\n",
       " '▁project',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁.',\n",
       " '▁What',\n",
       " '▁exactly',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁?',\n",
       " '▁According',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁definition',\n",
       " '▁of',\n",
       " '▁Buz',\n",
       " 'an',\n",
       " '▁T',\n",
       " '.',\n",
       " '▁and',\n",
       " '▁Buz',\n",
       " 'an',\n",
       " '▁B',\n",
       " '.',\n",
       " '▁(',\n",
       " '▁1999',\n",
       " '▁,',\n",
       " '▁Des',\n",
       " 's',\n",
       " 'ine',\n",
       " '▁-',\n",
       " '▁moi',\n",
       " '▁l',\n",
       " \"'\",\n",
       " 'intelligence',\n",
       " '▁.',\n",
       " '▁Paris',\n",
       " '▁:',\n",
       " '▁Les',\n",
       " '▁É',\n",
       " 'dition',\n",
       " 's',\n",
       " '▁d',\n",
       " \"'\",\n",
       " 'Organ',\n",
       " 'isation',\n",
       " '▁.',\n",
       " '▁)',\n",
       " '▁,',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁(',\n",
       " '▁or',\n",
       " '▁heuristic',\n",
       " '▁diagram',\n",
       " '▁)',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁graphic',\n",
       " '▁representation',\n",
       " '▁technique',\n",
       " '▁that',\n",
       " '▁follows',\n",
       " '▁the',\n",
       " '▁natural',\n",
       " '▁functioning',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁and',\n",
       " '▁allows',\n",
       " '▁the',\n",
       " '▁brain',\n",
       " \"▁'\",\n",
       " 's',\n",
       " '▁potential',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁released',\n",
       " '▁.',\n",
       " '▁Cf',\n",
       " '▁Annex',\n",
       " '1',\n",
       " '▁This',\n",
       " '▁tool',\n",
       " '▁has',\n",
       " '▁many',\n",
       " '▁advantages',\n",
       " '▁:',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁accessible',\n",
       " '▁to',\n",
       " '▁all',\n",
       " '▁and',\n",
       " '▁does',\n",
       " '▁not',\n",
       " '▁require',\n",
       " '▁significant',\n",
       " '▁material',\n",
       " '▁investment',\n",
       " '▁and',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁done',\n",
       " '▁quickly',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁scalable',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁allows',\n",
       " '▁categorization',\n",
       " '▁and',\n",
       " '▁linking',\n",
       " '▁of',\n",
       " '▁information',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁applied',\n",
       " '▁to',\n",
       " '▁any',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁situation',\n",
       " '▁:',\n",
       " '▁note',\n",
       " 'taking',\n",
       " '▁,',\n",
       " '▁problem',\n",
       " '▁solving',\n",
       " '▁,',\n",
       " '▁analysis',\n",
       " '▁,',\n",
       " '▁creation',\n",
       " '▁of',\n",
       " '▁new',\n",
       " '▁ideas',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁suitable',\n",
       " '▁for',\n",
       " '▁all',\n",
       " '▁people',\n",
       " '▁and',\n",
       " '▁is',\n",
       " '▁easy',\n",
       " '▁to',\n",
       " '▁learn',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁fun',\n",
       " '▁and',\n",
       " '▁encourages',\n",
       " '▁exchanges',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁makes',\n",
       " '▁visible',\n",
       " '▁the',\n",
       " '▁dimension',\n",
       " '▁of',\n",
       " '▁projects',\n",
       " '▁,',\n",
       " '▁opportunities',\n",
       " '▁,',\n",
       " '▁interconnections',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁synthesize',\n",
       " 's',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁makes',\n",
       " '▁the',\n",
       " '▁project',\n",
       " '▁understandable',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁allows',\n",
       " '▁you',\n",
       " '▁to',\n",
       " '▁explore',\n",
       " '▁ideas',\n",
       " '▁The',\n",
       " '▁creation',\n",
       " '▁of',\n",
       " '▁a',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁starts',\n",
       " '▁with',\n",
       " '▁an',\n",
       " '▁idea',\n",
       " '▁/',\n",
       " '▁problem',\n",
       " '▁located',\n",
       " '▁at',\n",
       " '▁its',\n",
       " '▁center',\n",
       " '▁.',\n",
       " '▁This',\n",
       " '▁starting',\n",
       " '▁point',\n",
       " '▁generates',\n",
       " '▁ideas',\n",
       " '▁/',\n",
       " '▁work',\n",
       " '▁areas',\n",
       " '▁,',\n",
       " '▁incremented',\n",
       " '▁around',\n",
       " '▁this',\n",
       " '▁center',\n",
       " '▁in',\n",
       " '▁a',\n",
       " '▁radial',\n",
       " '▁structure',\n",
       " '▁,',\n",
       " '▁which',\n",
       " '▁in',\n",
       " '▁turn',\n",
       " '▁is',\n",
       " '▁completed',\n",
       " '▁with',\n",
       " '▁as',\n",
       " '▁many',\n",
       " '▁branches',\n",
       " '▁as',\n",
       " '▁new',\n",
       " '▁ideas',\n",
       " '▁.',\n",
       " '▁This',\n",
       " '▁tool',\n",
       " '▁enables',\n",
       " '▁creativity',\n",
       " '▁and',\n",
       " '▁logic',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁mobilized',\n",
       " '▁,',\n",
       " '▁it',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁map',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁thoughts',\n",
       " '▁.',\n",
       " '▁Creativity',\n",
       " '▁is',\n",
       " '▁enhanced',\n",
       " '▁because',\n",
       " '▁participants',\n",
       " '▁feel',\n",
       " '▁comfortable',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁method',\n",
       " '▁.',\n",
       " '▁Application',\n",
       " '▁&',\n",
       " '▁Insight',\n",
       " '▁I',\n",
       " '▁start',\n",
       " '▁the',\n",
       " '▁process',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁creation',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁standing',\n",
       " '▁around',\n",
       " '▁a',\n",
       " '▁large',\n",
       " '▁board',\n",
       " '▁(',\n",
       " '▁white',\n",
       " '▁or',\n",
       " '▁paper',\n",
       " '▁board',\n",
       " '▁)',\n",
       " '▁.',\n",
       " '▁In',\n",
       " '▁the',\n",
       " '▁center',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁board',\n",
       " '▁,',\n",
       " '▁I',\n",
       " '▁write',\n",
       " '▁and',\n",
       " '▁highlight',\n",
       " '▁the',\n",
       " '▁topic',\n",
       " '▁to',\n",
       " '▁design',\n",
       " '▁.',\n",
       " '▁Through',\n",
       " '▁a',\n",
       " '▁series',\n",
       " '▁of',\n",
       " '▁questions',\n",
       " '▁,',\n",
       " '▁I',\n",
       " '▁guide',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁in',\n",
       " '▁modelling',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁.',\n",
       " '▁I',\n",
       " '▁adapt',\n",
       " '▁the',\n",
       " '▁series',\n",
       " '▁of',\n",
       " '▁questions',\n",
       " '▁according',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁topic',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁addressed',\n",
       " '▁.',\n",
       " '▁In',\n",
       " '▁the',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁questions',\n",
       " '▁,',\n",
       " '▁we',\n",
       " '▁can',\n",
       " '▁use',\n",
       " '▁:',\n",
       " '▁who',\n",
       " '▁,',\n",
       " '▁what',\n",
       " '▁,',\n",
       " '▁when',\n",
       " '▁,',\n",
       " '▁where',\n",
       " '▁,',\n",
       " '▁why',\n",
       " '▁,',\n",
       " '▁how',\n",
       " '▁,',\n",
       " '▁how',\n",
       " '▁much',\n",
       " '▁.',\n",
       " '▁The',\n",
       " '▁use',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁“',\n",
       " '▁why',\n",
       " '▁',\n",
       " '”',\n",
       " '▁is',\n",
       " '▁very',\n",
       " '▁interesting',\n",
       " '▁to',\n",
       " '▁understand',\n",
       " '▁the',\n",
       " '▁origin',\n",
       " '▁.',\n",
       " '▁By',\n",
       " '▁this',\n",
       " '▁way',\n",
       " '▁,',\n",
       " '▁the',\n",
       " '▁interviewed',\n",
       " '▁person',\n",
       " '▁free',\n",
       " 's',\n",
       " '▁itself',\n",
       " '▁from',\n",
       " '▁paradigms',\n",
       " '▁and',\n",
       " '▁thus',\n",
       " '▁dares',\n",
       " '▁to',\n",
       " '▁propose',\n",
       " '▁new',\n",
       " '▁ideas',\n",
       " '▁/',\n",
       " '▁ways',\n",
       " '▁of',\n",
       " '▁functioning',\n",
       " '▁.',\n",
       " '▁I',\n",
       " '▁plan',\n",
       " '▁two',\n",
       " '▁hours',\n",
       " '▁for',\n",
       " '▁a',\n",
       " '▁workshop',\n",
       " '▁.',\n",
       " '▁Design',\n",
       " '▁Thinking',\n",
       " '▁for',\n",
       " '▁innovation',\n",
       " '▁reflex',\n",
       " 'ion',\n",
       " '▁-',\n",
       " '▁Avril',\n",
       " '▁2021',\n",
       " '▁-',\n",
       " '▁Nathalie',\n",
       " '▁S',\n",
       " 'ylla',\n",
       " '▁After',\n",
       " '▁modelling',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁on',\n",
       " '▁paper',\n",
       " '▁,',\n",
       " '▁I',\n",
       " '▁propose',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁participants',\n",
       " '▁a',\n",
       " '▁digital',\n",
       " '▁visualization',\n",
       " '▁of',\n",
       " '▁their',\n",
       " '▁work',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁addition',\n",
       " '▁of',\n",
       " '▁color',\n",
       " '▁codes',\n",
       " '▁,',\n",
       " '▁images',\n",
       " '▁and',\n",
       " '▁interconnections',\n",
       " '▁.',\n",
       " '▁This',\n",
       " '▁second',\n",
       " '▁workshop',\n",
       " '▁also',\n",
       " '▁last',\n",
       " 's',\n",
       " '▁two',\n",
       " '▁hours',\n",
       " '▁and',\n",
       " '▁allows',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁to',\n",
       " '▁evolve',\n",
       " '▁.',\n",
       " '▁Once',\n",
       " '▁familiarized',\n",
       " '▁with',\n",
       " '▁it',\n",
       " '▁,',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁discover',\n",
       " '▁the',\n",
       " '▁power',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁tool',\n",
       " '▁.',\n",
       " '▁Then',\n",
       " '▁,',\n",
       " '▁the',\n",
       " '▁second',\n",
       " '▁workshop',\n",
       " '▁brings',\n",
       " '▁out',\n",
       " '▁even',\n",
       " '▁more',\n",
       " '▁ideas',\n",
       " '▁and',\n",
       " '▁constructive',\n",
       " '▁exchanges',\n",
       " '▁between',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁.',\n",
       " '▁Around',\n",
       " '▁this',\n",
       " '▁new',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁,',\n",
       " '▁they',\n",
       " '▁have',\n",
       " '▁learned',\n",
       " '▁to',\n",
       " '▁work',\n",
       " '▁together',\n",
       " '▁and',\n",
       " '▁want',\n",
       " '▁to',\n",
       " '▁make',\n",
       " '▁visible',\n",
       " '▁the',\n",
       " '▁untold',\n",
       " '▁ideas',\n",
       " '▁.',\n",
       " '▁I',\n",
       " '▁now',\n",
       " '▁present',\n",
       " '▁all',\n",
       " '▁the',\n",
       " '▁projects',\n",
       " '▁I',\n",
       " '▁manage',\n",
       " '▁in',\n",
       " '▁this',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁format',\n",
       " '▁in',\n",
       " '▁order',\n",
       " '▁to',\n",
       " '▁ease',\n",
       " '▁rapid',\n",
       " '▁understanding',\n",
       " '▁for',\n",
       " '▁decision',\n",
       " '▁-',\n",
       " '▁makers',\n",
       " '▁.',\n",
       " '▁These',\n",
       " '▁presentations',\n",
       " '▁are',\n",
       " '▁the',\n",
       " '▁core',\n",
       " '▁of',\n",
       " '▁my',\n",
       " '▁business',\n",
       " '▁models',\n",
       " '▁.',\n",
       " '▁The',\n",
       " '▁decision',\n",
       " '▁-',\n",
       " '▁makers',\n",
       " '▁are',\n",
       " '▁thus',\n",
       " '▁able',\n",
       " '▁to',\n",
       " '▁identify',\n",
       " '▁the',\n",
       " '▁opportunities',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁projects',\n",
       " '▁and',\n",
       " '▁can',\n",
       " '▁take',\n",
       " '▁quick',\n",
       " '▁decisions',\n",
       " '▁to',\n",
       " '▁validate',\n",
       " '▁them',\n",
       " '▁.',\n",
       " '▁They',\n",
       " '▁find',\n",
       " '▁answers',\n",
       " '▁to',\n",
       " '▁their',\n",
       " '▁questions',\n",
       " '▁thank',\n",
       " '▁to',\n",
       " '▁a',\n",
       " '▁schematic',\n",
       " '▁representation',\n",
       " '▁.',\n",
       " '▁Approach',\n",
       " '▁What',\n",
       " '▁I',\n",
       " '▁find',\n",
       " '▁amazing',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁facilitation',\n",
       " '▁of',\n",
       " '▁this',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁workshop',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁participants',\n",
       " '▁commitment',\n",
       " '▁for',\n",
       " '▁the',\n",
       " '▁project',\n",
       " '▁.',\n",
       " '▁This',\n",
       " '▁tool',\n",
       " '▁helps',\n",
       " '▁to',\n",
       " '▁give',\n",
       " '▁meaning',\n",
       " '▁.',\n",
       " '▁The',\n",
       " '▁participants',\n",
       " '▁appropriate',\n",
       " '▁the',\n",
       " '▁story',\n",
       " '▁and',\n",
       " '▁want',\n",
       " '▁to',\n",
       " '▁keep',\n",
       " '▁writing',\n",
       " '▁it',\n",
       " '▁.',\n",
       " '▁Then',\n",
       " '▁,',\n",
       " '▁they',\n",
       " '▁easily',\n",
       " '▁become',\n",
       " '▁actors',\n",
       " '▁or',\n",
       " '▁sponsors',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁project',\n",
       " '▁.',\n",
       " '▁A',\n",
       " '▁trust',\n",
       " '▁relationship',\n",
       " '▁is',\n",
       " '▁built',\n",
       " '▁,',\n",
       " '▁thus',\n",
       " '▁facilitating',\n",
       " '▁the',\n",
       " '▁implementation',\n",
       " '▁of',\n",
       " '▁related',\n",
       " '▁actions',\n",
       " '▁.',\n",
       " '▁Design',\n",
       " '▁Thinking',\n",
       " '▁for',\n",
       " '▁innovation',\n",
       " '▁reflex',\n",
       " 'ion',\n",
       " '▁-',\n",
       " '▁Avril',\n",
       " '▁2021',\n",
       " '▁-',\n",
       " '▁Nathalie',\n",
       " '▁S',\n",
       " 'ylla',\n",
       " '▁Annex',\n",
       " '▁1',\n",
       " '▁:',\n",
       " '▁Mind',\n",
       " '▁Map',\n",
       " '▁Shared',\n",
       " '▁facilities',\n",
       " '▁project',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: 512?が上限であるのに対し、NER対象のテキストが512よりも長い場合が多いため、適したモデルにする\n",
    "# DeBERTaあたりは、512を超えるテキストに対応していたような\n",
    "# example = train_dataset[30]\n",
    "example = train_dataset[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.602698Z",
     "iopub.status.busy": "2024-02-17T10:47:19.602532Z",
     "iopub.status.idle": "2024-02-17T10:47:19.605795Z",
     "shell.execute_reply": "2024-02-17T10:47:19.605299Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# labelを変換する\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-NAME_STUDENT\",\n",
    "    2: \"I-NAME_STUDENT\",\n",
    "    3: \"B-EMAIL\",\n",
    "    4: \"I-EMAIL\",\n",
    "    5: \"B-USERNAME\",\n",
    "    6: \"I-USERNAME\",\n",
    "    7: \"B-ID_NUM\",\n",
    "    8: \"I-ID_NUM\",\n",
    "    9: \"B-PHONE_NUM\",\n",
    "    10: \"I-PHONE_NUM\",\n",
    "    11: \"B-URL_PERSONAL\",\n",
    "    12: \"I-URL_PERSONAL\",\n",
    "    13: \"B-STREET_ADDRESS\",\n",
    "    14: \"I-STREET_ADDRESS\",\n",
    "}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "# def label2id_func(example):\n",
    "#     example[\"labels\"] = [label2id[tag] for tag in example[\"labels\"]]\n",
    "#     return example\n",
    "\n",
    "\n",
    "# labele2id_train_dataset = train_dataset.map(label2id_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.607827Z",
     "iopub.status.busy": "2024-02-17T10:47:19.607671Z",
     "iopub.status.idle": "2024-02-17T10:47:19.634341Z",
     "shell.execute_reply": "2024-02-17T10:47:19.633771Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "    \"\"\"\n",
    "    与えられたtokenとlabelから、\n",
    "    今回のtokenizerで区切った場合のtokenとlabelを作成する。\n",
    "    \"\"\"\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l, ws in zip(\n",
    "        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n",
    "    ):\n",
    "        text.append(t)\n",
    "        # 文字数分だけ、該当のラベルを追加する\n",
    "        labels.extend([l] * len(t))\n",
    "\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "        # text -> ['Design', ' ']\n",
    "        # labels -> ['O', 'O', 'O', 'O', 'O', 'O', 'O'] (6文字分 + 空白1文字分)\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\n",
    "        \"\".join(text),\n",
    "        return_offsets_mapping=True,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # offset_mappingの各エントリは、トークンが元のテキストのどの範囲（開始位置と終了位置）にマッピングされるかを示す\n",
    "        # タプルまたはリストで構成されます。\n",
    "\n",
    "        # CLS tokenの対応\n",
    "        # CLSやSEPには必ず(start_idx, end_idx) = (0, 0)が割り当てられる\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # 空白が存在する時は、offset_mappingのstart_idxを+1する\n",
    "        # DeBERTaV2Tokenizerは、空白を文字の先頭に▁としてくっつけるため。\n",
    "        # NOTE: もし空白を▁として文字の先頭にくっつけるないtokenizerの場合は、不要\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    # Q: token_labelsは何の長さ？\n",
    "    # A: 今回のtokenizerで区切った時の、tokenに該当するlabel\n",
    "    # 例:\n",
    "    # 与えられたtoken example[\"tokens\"][:10]\n",
    "    # -> ['Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie']\n",
    "    # 今回のtokenizerで区切ったtoken　tokenizer.convert_ids_to_tokens(tokenized.input_ids[:10])\n",
    "    # -> ['[CLS]', '▁Design', '▁Thinking', '▁for', '▁innovation', '▁reflex', 'ion', '-', 'Av', 'ril']\n",
    "    # 文字数が違う！！！\n",
    "    # 最初に与えられたtokenとそのlabelだと、今回のtokenizerで区切った場合のラベルが分からない。\n",
    "    # 今回のtokenizerで区切った場合のtokenとラベルを作成した。\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": length}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize,\n",
    "    fn_kwargs={\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"label2id\": label2id,\n",
    "        \"max_length\": TRAINING_MAX_LENGTH,\n",
    "    },\n",
    "    num_proc=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.636495Z",
     "iopub.status.busy": "2024-02-17T10:47:19.636315Z",
     "iopub.status.idle": "2024-02-17T10:47:19.645062Z",
     "shell.execute_reply": "2024-02-17T10:47:19.644487Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train_dataset[2]\n",
    "\n",
    "for t, l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n",
    "    if l != \"O\":\n",
    "        print((t, l))\n",
    "\n",
    "print(\"*\" * 100)\n",
    "\n",
    "for t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n",
    "    if id2label[l] != \"O\":\n",
    "        print((t, id2label[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.647149Z",
     "iopub.status.busy": "2024-02-17T10:47:19.646983Z",
     "iopub.status.idle": "2024-02-17T10:47:19.650579Z",
     "shell.execute_reply": "2024-02-17T10:47:19.650049Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-NAME_STUDENT',\n",
       " 'I-NAME_STUDENT',\n",
       " 'B-EMAIL',\n",
       " 'I-EMAIL',\n",
       " 'B-USERNAME',\n",
       " 'I-USERNAME',\n",
       " 'B-ID_NUM',\n",
       " 'I-ID_NUM',\n",
       " 'B-PHONE_NUM',\n",
       " 'I-PHONE_NUM',\n",
       " 'B-URL_PERSONAL',\n",
       " 'I-URL_PERSONAL',\n",
       " 'B-STREET_ADDRESS',\n",
       " 'I-STREET_ADDRESS']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = list(label2id.keys())\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.653024Z",
     "iopub.status.busy": "2024-02-17T10:47:19.652862Z",
     "iopub.status.idle": "2024-02-17T10:47:19.656079Z",
     "shell.execute_reply": "2024-02-17T10:47:19.655594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.658374Z",
     "iopub.status.busy": "2024-02-17T10:47:19.658220Z",
     "iopub.status.idle": "2024-02-17T10:47:19.661099Z",
     "shell.execute_reply": "2024-02-17T10:47:19.660600Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def tokenize_and_align_labels(examples):\n",
    "#     \"\"\"\n",
    "#     tokenizeした文字列をinput_idsとして追加する\n",
    "#     labelsには、special tokenが-100として扱われたデータが入る\n",
    "#     \"\"\"\n",
    "#     tokenized_inputs = tokenizer(\n",
    "#         examples[\"tokens\"],\n",
    "#         truncation=True,\n",
    "#         is_split_into_words=True,\n",
    "#         max_length=TRAINING_MAX_LENGTH,\n",
    "#     )\n",
    "\n",
    "#     labels = []\n",
    "#     for i, label in enumerate(examples[\"labels\"]):\n",
    "#         # トークン化されたシーケンス内の各トークンが元のテキスト内のどの単語に対応するかを示すIDを提供します。\n",
    "#         # 例えば、元のテキストが \"Hello, world!\" で、トークン化されたシーケンスが [\"Hello\", \",\", \"world\", \"!\"] の場合\n",
    "#         # `word_ids`メソッドは [0, None, 1, None] を返します。\n",
    "#         # これは、\"Hello\" が最初の単語（インデックス0）、\",\" が単語に属さない（None）、\"world\" が2番目の単語（インデックス1）、\"!\" が単語に属さない（None）ことを示します。\n",
    "#         word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "#         previous_word_idx = None\n",
    "#         label_ids = []\n",
    "#         for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "#             if word_idx is None:\n",
    "#                 label_ids.append(-100)\n",
    "#             elif (\n",
    "#                 word_idx != previous_word_idx\n",
    "#             ):  # subwordの場合、同じword_idxが連続している。最初のtoken以外は-100にする\n",
    "#                 label_ids.append(label[word_idx])\n",
    "#             else:\n",
    "#                 label_ids.append(-100)\n",
    "#             previous_word_idx = word_idx\n",
    "#         labels.append(label_ids)\n",
    "\n",
    "#     tokenized_inputs[\"labels\"] = labels\n",
    "#     return tokenized_inputs\n",
    "\n",
    "\n",
    "# tokenized_train_dataset = labele2id_train_dataset.map(\n",
    "#     tokenize_and_align_labels, batched=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.663045Z",
     "iopub.status.busy": "2024-02-17T10:47:19.662894Z",
     "iopub.status.idle": "2024-02-17T10:47:19.665156Z",
     "shell.execute_reply": "2024-02-17T10:47:19.664631Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.667016Z",
     "iopub.status.busy": "2024-02-17T10:47:19.666862Z",
     "iopub.status.idle": "2024-02-17T10:47:19.669430Z",
     "shell.execute_reply": "2024-02-17T10:47:19.668895Z"
    }
   },
   "outputs": [],
   "source": [
    "# pad_to_multiple_of\n",
    "# paddingの際に、指定した数の倍数になるように、各サンプルの長さを揃える\n",
    "# ハードウェアの要件に合致することで、計算効率が良くなる可能性がある\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, pad_to_multiple_of=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.671385Z",
     "iopub.status.busy": "2024-02-17T10:47:19.671232Z",
     "iopub.status.idle": "2024-02-17T10:47:19.844821Z",
     "shell.execute_reply": "2024-02-17T10:47:19.836807Z"
    }
   },
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.847812Z",
     "iopub.status.busy": "2024-02-17T10:47:19.847606Z",
     "iopub.status.idle": "2024-02-17T10:47:19.852568Z",
     "shell.execute_reply": "2024-02-17T10:47:19.852079Z"
    }
   },
   "outputs": [],
   "source": [
    "def f5_score(precision: float, recall: float, beta: int = 5):\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    # seqevalのmetrics関数を使用して、精度、再現率、F1スコア、正解率を計算\n",
    "    precision = results[\"overall_precision\"]\n",
    "    recall = results[\"overall_recall\"]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "        \"f5score\": f5_score(precision, recall),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:19.854681Z",
     "iopub.status.busy": "2024-02-17T10:47:19.854503Z",
     "iopub.status.idle": "2024-02-17T10:47:20.605069Z",
     "shell.execute_reply": "2024-02-17T10:47:20.604446Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:20.607603Z",
     "iopub.status.busy": "2024-02-17T10:47:20.607413Z",
     "iopub.status.idle": "2024-02-17T10:47:20.619399Z",
     "shell.execute_reply": "2024-02-17T10:47:20.618924Z"
    }
   },
   "outputs": [],
   "source": [
    "# evalデータの用意\n",
    "split_dataset = train_dataset.train_test_split(test_size=0.2)\n",
    "train_valid_dataset = DatasetDict(\n",
    "    {\"train\": split_dataset[\"train\"], \"valid\": split_dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:20.621730Z",
     "iopub.status.busy": "2024-02-17T10:47:20.621551Z",
     "iopub.status.idle": "2024-02-17T10:47:20.625041Z",
     "shell.execute_reply": "2024-02-17T10:47:20.624510Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['provided_labels', 'document', 'trailing_whitespace', 'tokens', 'full_text', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'],\n",
       "        num_rows: 5445\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['provided_labels', 'document', 'trailing_whitespace', 'tokens', 'full_text', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'],\n",
       "        num_rows: 1362\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:20.627038Z",
     "iopub.status.busy": "2024-02-17T10:47:20.626869Z",
     "iopub.status.idle": "2024-02-17T10:47:21.918941Z",
     "shell.execute_reply": "2024-02-17T10:47:21.918311Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=LOG_PATH,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,  # 32はだめ、性能がepoch0の時、precision0.31→0.00、Recall0.25→0.00に落ちる\n",
    "    per_device_eval_batch_size=16,  # 32,↑同様、バッチサイズが非常に重要なパラメーターであるとも言える\n",
    "    # num_train_epochs=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"f5score\",  # add\n",
    "    greater_is_better=True,  # add\n",
    "    warmup_ratio=0.1,  # add\n",
    "    lr_scheduler_type=\"cosine\",  # add\n",
    "    report_to=REPORT_TO,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-17T10:47:21.923540Z",
     "iopub.status.busy": "2024-02-17T10:47:21.923364Z",
     "iopub.status.idle": "2024-02-17T10:47:25.396017Z",
     "shell.execute_reply": "2024-02-17T10:47:25.395125Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1023' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1023 : < :, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 47.54 GiB total capacity; 43.55 GiB already allocated; 651.12 MiB free; 44.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# モデルの学習\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m cv_score \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_f5score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# モデルの保存\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:2772\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2772\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1404\u001b[0m, in \u001b[0;36mDebertaV2ForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1404\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1417\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1070\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1062\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1063\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1064\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1068\u001b[0m )\n\u001b[0;32m-> 1070\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:514\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    504\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    505\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    506\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output_attentions,\n\u001b[1;32m    512\u001b[0m     )\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    524\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:362\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    355\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m ):\n\u001b[0;32m--> 362\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    371\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:293\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    286\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    292\u001b[0m ):\n\u001b[0;32m--> 293\u001b[0m     self_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    302\u001b[0m         self_output, att_matrix \u001b[38;5;241m=\u001b[39m self_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:721\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention:\n\u001b[1;32m    720\u001b[0m     rel_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_dropout(rel_embeddings)\n\u001b[0;32m--> 721\u001b[0m     rel_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisentangled_attention_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rel_att \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m rel_att\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:824\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.disentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    818\u001b[0m     p2c_att \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(key_layer, pos_query_layer\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    819\u001b[0m     p2c_att \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    820\u001b[0m         p2c_att,\n\u001b[1;32m    821\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    822\u001b[0m         index\u001b[38;5;241m=\u001b[39mp2c_pos\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand([query_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), key_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), key_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)]),\n\u001b[1;32m    823\u001b[0m     )\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 824\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mp2c_att\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp2c_att\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 47.54 GiB total capacity; 43.55 GiB already allocated; 651.12 MiB free; 44.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "trainer.train()\n",
    "cv_score = trainer.evaluate()[\"eval_f5score\"]\n",
    "# モデルの保存\n",
    "trainer.save_model(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_OUTPUT_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_OUTPUT_PATH)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \".\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(train_valid_dataset[\"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make CV DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_preds(trainer, valid_dataset):\n",
    "    \"\"\"\n",
    "    trainerを用いてvalid_datasetに対する予測を行う\n",
    "    \"\"\"\n",
    "    predictions = trainer.predict(valid_dataset).predictions\n",
    "    preds_final = predictions.argmax(-1)\n",
    "\n",
    "    return preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer):\n",
    "    text = []\n",
    "    token_map = []\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n",
    "        text.append(t)\n",
    "        token_map.extend([idx] * len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            token_map.append(-1)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    # tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=INFERENCE_MAX_LENGTH)\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True)\n",
    "\n",
    "    return {\n",
    "        **tokenized,\n",
    "        \"token_map\": token_map,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_part(preds_final, valid_dataset):\n",
    "    triplets = []\n",
    "    document, token, label, token_str = [], [], [], []\n",
    "    for p, token_map, offsets, tokens, doc in zip(\n",
    "        preds_final,\n",
    "        valid_dataset[\"token_map\"],\n",
    "        valid_dataset[\"offset_mapping\"],\n",
    "        valid_dataset[\"tokens\"],\n",
    "        valid_dataset[\"document\"],\n",
    "    ):\n",
    "        for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "            label_pred = id2label[token_pred]\n",
    "\n",
    "            if start_idx + end_idx == 0:\n",
    "                continue\n",
    "\n",
    "            if token_map[start_idx] == -1:\n",
    "                start_idx += 1\n",
    "\n",
    "            # ignore \"\\n\\n\"\n",
    "            while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "                start_idx += 1\n",
    "\n",
    "            if start_idx >= len(token_map):\n",
    "                break\n",
    "\n",
    "            token_id = token_map[start_idx]\n",
    "\n",
    "            # ignore \"O\" predictions and whitespace preds\n",
    "            if label_pred != \"O\" and token_id != -1:\n",
    "                triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "                if triplet not in triplets:\n",
    "                    document.append(doc)\n",
    "                    token.append(token_id)\n",
    "                    label.append(label_pred)\n",
    "                    token_str.append(tokens[token_id])\n",
    "                    triplets.append(triplet)\n",
    "\n",
    "    return document, token, label, token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correct_df(train: pl.DataFrame):\n",
    "    # 学習データから、outputと同様のデータフレームを作成する\n",
    "    outputs = []\n",
    "    for document_id, token, label in zip(\n",
    "        train[\"document\"], train[\"tokens\"], train[\"labels\"]\n",
    "    ):\n",
    "        for token, (token_str, label_one) in enumerate(zip(token, label)):\n",
    "            if label_one != \"O\":\n",
    "                outputs.append((document_id, token, token_str, label_one))\n",
    "    return pl.DataFrame(outputs, schema=[\"document\", \"token\", \"label\", \"token_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correct_pred_join_df(\n",
    "    train_correct_df: pl.DataFrame, valid_pred_df: pl.DataFrame\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    validで利用したdocumentのみを抽出し、train_correct_dfとvalid_pred_dfを結合して、documentごとに比較できるようにする\n",
    "    \"\"\"\n",
    "    out = train_correct_df.filter(\n",
    "        pl.col(\"document\").is_in(valid_pred_df[\"document\"])\n",
    "    ).join(valid_pred_df, on=[\"document\", \"token\"], how=\"outer\", suffix=\"_pred\")\n",
    "\n",
    "    joined_dfs = []\n",
    "    for document in out[\"document\"].unique().to_list():\n",
    "        if document is None:\n",
    "            continue\n",
    "        joined_df_per_document = out.filter(\n",
    "            (pl.col(\"document\") == document) | (pl.col(\"document_pred\") == document)\n",
    "        )\n",
    "        joined_dfs.append(joined_df_per_document)\n",
    "\n",
    "    return pl.concat(joined_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# main\n",
    "valid_dataset = train_dataset.filter(\n",
    "    lambda example: example[\"document\"] in train_valid_dataset[\"valid\"][\"document\"]\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize, fn_kwargs={\"tokenizer\": tokenizer}, num_proc=3\n",
    ")\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": TRAINING_MAX_LENGTH}, num_proc=3\n",
    "# )\n",
    "\n",
    "valid_preds = get_valid_preds(trainer, valid_dataset)\n",
    "\n",
    "document, token, label, token_str = get_output_part(valid_preds, valid_dataset)\n",
    "\n",
    "valid_pred_df = pl.DataFrame(\n",
    "    [document, token, label, token_str],\n",
    "    schema=[\"document\", \"token\", \"label\", \"token_str\"],\n",
    ")\n",
    "\n",
    "train_correct_df = make_correct_df(train)\n",
    "\n",
    "valid_correct_pred_df = make_correct_pred_join_df(train_correct_df, valid_pred_df)\n",
    "\n",
    "# wandbにuploadする\n",
    "if not DEBUG:\n",
    "    tbl = wandb.Table(data=valid_correct_pred_df.to_pandas())\n",
    "    wandb.log({\"valid_correct_pred_df\": tbl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_correct_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(\"cp /notebooks/pll_data_detection/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "    dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "    dataset_metadata[\"title\"] = dataset_name\n",
    "    with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "\n",
    "if (not DEBUG) and UPLOAD_DATA:\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MODEL_OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
