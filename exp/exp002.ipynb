{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "- CVスコアを計算する\n",
    "- Validデータに対する現在のモデルの出力を作成する(=1)\n",
    "- 1をwandbに記録する https://docs.wandb.ai/ja/guides/track/log/working-with-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"e02-make-val-out\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME}\"\n",
    "LOG_PATH = f\"pll_data_detection/log/{EXP_NAME}\"\n",
    "MODEL_OUTPUT_PATH = f\"pll_data_detection/trained_models/{EXP_NAME}\"\n",
    "DEBUG = False\n",
    "UPLOAD_DATA = True\n",
    "REPORT_TO = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /usr/local/lib/python3.9/dist-packages (0.20.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.9/dist-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (4.64.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (0.20.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (0.15.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (2.28.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.37.2) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.37.2) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.37.2) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.37.2) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets==2.16.1 in /usr/local/lib/python3.9/dist-packages (2.16.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (0.70.13)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (0.3.5.1)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (2023.10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (5.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (1.5.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (1.23.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (2.28.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (0.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (0.20.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (3.9.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (6.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.16.1) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.16.1) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.16.1) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: evaluate==0.4.1 in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (1.23.4)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (0.70.13)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (23.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (3.2.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (2.16.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (2.28.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate==0.4.1) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.8.3)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (0.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (2.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate==0.4.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate==0.4.1) (2022.7.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (18.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.3.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate==0.4.1) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from seqeval==1.2.2) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval==1.2.2) (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.9.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.12.1+cu116)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->accelerate) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.6.5)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.28.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in /usr/lib/python3/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "ERROR: unknown command \"iinstall\" - maybe you meant \"install\"\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: black in /usr/local/lib/python3.9/dist-packages (24.1.1)\n",
      "Requirement already satisfied: isort in /usr/local/lib/python3.9/dist-packages (5.13.2)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.9/dist-packages (from black) (23.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from black) (4.4.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.9/dist-packages (from black) (2.6.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from black) (8.1.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from black) (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install polars\n",
    "%pip install transformers==4.37.2\n",
    "%pip install datasets==2.16.1\n",
    "%pip install evaluate==0.4.1\n",
    "%pip install seqeval==1.2.2\n",
    "%pip install accelerate\n",
    "%pip install python-dotenv\n",
    "%pip install kaggle\n",
    "%pip iinstall wandb==0.16.3\n",
    "\n",
    "# formatter\n",
    "%pip install black isort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TokenClassificationPipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "assert transformers.__version__ == \"4.37.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "assert datasets.__version__ == \"2.16.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "assert evaluate.__version__ == \"0.4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240212_044858-6vyq0631</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sinchir0/pll/runs/6vyq0631\" target=\"_blank\">e02-make-val-out</a></strong> to <a href=\"https://wandb.ai/sinchir0/pll\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "if not DEBUG:\n",
    "    load_dotenv(\"pll_data_detection/.env\")\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=\"pll\", name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 12 04:49:01 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   33C    P8    26W / 300W |   7571MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>full_text</th><th>tokens</th><th>trailing_whitespace</th><th>labels</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[bool]</td><td>list[str]</td></tr></thead><tbody><tr><td>7</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>10</td><td>&quot;Diego Estrada\n",
       "…</td><td>[&quot;Diego&quot;, &quot;Estrada&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;B-NAME_STUDENT&quot;, &quot;I-NAME_STUDENT&quot;, … &quot;O&quot;]</td></tr><tr><td>16</td><td>&quot;Reporting proc…</td><td>[&quot;Reporting&quot;, &quot;process&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>20</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>56</td><td>&quot;Assignment:  V…</td><td>[&quot;Assignment&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────┬─────────────────────┬─────────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ document ┆ full_text           ┆ tokens              ┆ trailing_whitespace ┆ labels              │\n",
       "│ ---      ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---                 │\n",
       "│ i64      ┆ str                 ┆ list[str]           ┆ list[bool]          ┆ list[str]           │\n",
       "╞══════════╪═════════════════════╪═════════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 7        ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ innovation r…       ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 10       ┆ Diego Estrada       ┆ [\"Diego\",           ┆ [true, false, …     ┆ [\"B-NAME_STUDENT\",  │\n",
       "│          ┆                     ┆ \"Estrada\", … \"      ┆ false]              ┆ \"I-NAME_STUDE…      │\n",
       "│          ┆ Design Thinking A…  ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 16       ┆ Reporting process   ┆ [\"Reporting\",       ┆ [true, false, …     ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆ \"process\", … \"      ┆ false]              ┆                     │\n",
       "│          ┆ by Gilberto G…      ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 20       ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ Innovation          ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆ …                   ┆ \"]                  ┆                     ┆                     │\n",
       "│ 56       ┆ Assignment:  Visual ┆ [\"Assignment\", \":\", ┆ [false, false, …    ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ ization Refle…      ┆ … \"                 ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "└──────────┴─────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ確認用\n",
    "train = pl.read_json(\"pll_data_detection/train.json\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>full_text</th><th>tokens</th><th>trailing_whitespace</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[bool]</td></tr></thead><tbody><tr><td>7</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>10</td><td>&quot;Diego Estrada\n",
       "…</td><td>[&quot;Diego&quot;, &quot;Estrada&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>16</td><td>&quot;Reporting proc…</td><td>[&quot;Reporting&quot;, &quot;process&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>20</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>56</td><td>&quot;Assignment:  V…</td><td>[&quot;Assignment&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td></tr><tr><td>86</td><td>&quot;Cheese Startup…</td><td>[&quot;Cheese&quot;, &quot;Startup&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>93</td><td>&quot;Silvia Villalo…</td><td>[&quot;Silvia&quot;, &quot;Villalobos&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>104</td><td>&quot;Storytelling  …</td><td>[&quot;Storytelling&quot;, &quot; &quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>112</td><td>&quot;Reflection – L…</td><td>[&quot;Reflection&quot;, &quot;–&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>123</td><td>&quot;Gandhi Institu…</td><td>[&quot;Gandhi&quot;, &quot;Institute&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌──────────┬──────────────────────────────┬──────────────────────────────┬─────────────────────────┐\n",
       "│ document ┆ full_text                    ┆ tokens                       ┆ trailing_whitespace     │\n",
       "│ ---      ┆ ---                          ┆ ---                          ┆ ---                     │\n",
       "│ i64      ┆ str                          ┆ list[str]                    ┆ list[bool]              │\n",
       "╞══════════╪══════════════════════════════╪══════════════════════════════╪═════════════════════════╡\n",
       "│ 7        ┆ Design Thinking for          ┆ [\"Design\", \"Thinking\", … \"   ┆ [true, true, … false]   │\n",
       "│          ┆ innovation r…                ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 10       ┆ Diego Estrada                ┆ [\"Diego\", \"Estrada\", … \"     ┆ [true, false, … false]  │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ Design Thinking A…           ┆ \"]                           ┆                         │\n",
       "│ 16       ┆ Reporting process            ┆ [\"Reporting\", \"process\", … \" ┆ [true, false, … false]  │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ by Gilberto G…               ┆ \"]                           ┆                         │\n",
       "│ 20       ┆ Design Thinking for          ┆ [\"Design\", \"Thinking\", … \"   ┆ [true, true, … false]   │\n",
       "│          ┆ Innovation                   ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│          ┆ …                            ┆                              ┆                         │\n",
       "│ 56       ┆ Assignment:                  ┆ [\"Assignment\", \":\", … \"      ┆ [false, false, … false] │\n",
       "│          ┆ Visualization Refle…         ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 86       ┆ Cheese Startup - Learning    ┆ [\"Cheese\", \"Startup\", … \"    ┆ [true, true, … false]   │\n",
       "│          ┆ Launch…                      ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 93       ┆ Silvia Villalobos            ┆ [\"Silvia\", \"Villalobos\", … \" ┆ [true, false, … false]  │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ Challenge:                   ┆ \"]                           ┆                         │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ T…                           ┆                              ┆                         │\n",
       "│ 104      ┆ Storytelling  The Path to    ┆ [\"Storytelling\", \" \", … \"    ┆ [true, false, … false]  │\n",
       "│          ┆ Innova…                      ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 112      ┆ Reflection – Learning Launch ┆ [\"Reflection\", \"–\", … \"      ┆ [true, true, … false]   │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ Fr…                          ┆ \"]                           ┆                         │\n",
       "│ 123      ┆ Gandhi Institute of          ┆ [\"Gandhi\", \"Institute\", … \"  ┆ [true, true, … false]   │\n",
       "│          ┆ Technology a…                ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "└──────────┴──────────────────────────────┴──────────────────────────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ確認用\n",
    "test = pl.read_json(\"pll_data_detection/test.json\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"json\", data_files={\"train\": \"pll_data_detection/train.json\"}, split=\"train\"\n",
    ")\n",
    "test_dataset = load_dataset(\n",
    "    \"json\", data_files={\"test\": \"pll_data_detection/test.json\"}, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "if DEBUG:\n",
    "    train_dataset = train_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'full_text', 'trailing_whitespace', 'document', 'labels'],\n",
       "    num_rows: 6807\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'design',\n",
       " 'thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflex',\n",
       " '##ion',\n",
       " '-',\n",
       " 'av',\n",
       " '##ril']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: 512?が上限であるのに対し、NER対象のテキストが512よりも長い場合が多いため、適したモデルにする\n",
    "# DeBERTaあたりは、512を超えるテキストに対応していたような\n",
    "example = train_dataset[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelを変換する\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-NAME_STUDENT\",\n",
    "    2: \"I-NAME_STUDENT\",\n",
    "    3: \"B-EMAIL\",\n",
    "    4: \"I-EMAIL\",\n",
    "    5: \"B-USERNAME\",\n",
    "    6: \"I-USERNAME\",\n",
    "    7: \"B-ID_NUM\",\n",
    "    8: \"I-ID_NUM\",\n",
    "    9: \"B-PHONE_NUM\",\n",
    "    10: \"I-PHONE_NUM\",\n",
    "    11: \"B-URL_PERSONAL\",\n",
    "    12: \"I-URL_PERSONAL\",\n",
    "    13: \"B-STREET_ADDRESS\",\n",
    "    14: \"I-STREET_ADDRESS\",\n",
    "}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "def label2id_func(example):\n",
    "    example[\"labels\"] = [label2id[tag] for tag in example[\"labels\"]]\n",
    "    return example\n",
    "\n",
    "\n",
    "labele2id_train_dataset = train_dataset.map(label2id_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-NAME_STUDENT',\n",
       " 'I-NAME_STUDENT',\n",
       " 'B-EMAIL',\n",
       " 'I-EMAIL',\n",
       " 'B-USERNAME',\n",
       " 'I-USERNAME',\n",
       " 'B-ID_NUM',\n",
       " 'I-ID_NUM',\n",
       " 'B-PHONE_NUM',\n",
       " 'I-PHONE_NUM',\n",
       " 'B-URL_PERSONAL',\n",
       " 'I-URL_PERSONAL',\n",
       " 'B-STREET_ADDRESS',\n",
       " 'I-STREET_ADDRESS']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = list(label2id.keys())\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        # トークン化されたシーケンス内の各トークンが元のテキスト内のどの単語に対応するかを示すIDを提供します。\n",
    "        # 例えば、元のテキストが \"Hello, world!\" で、トークン化されたシーケンスが [\"Hello\", \",\", \"world\", \"!\"] の場合\n",
    "        # `word_ids`メソッドは [0, None, 1, None] を返します。\n",
    "        # これは、\"Hello\" が最初の単語（インデックス0）、\",\" が単語に属さない（None）、\"world\" が2番目の単語（インデックス1）、\"!\" が単語に属さない（None）ことを示します。\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif (\n",
    "                word_idx != previous_word_idx\n",
    "            ):  # subwordの場合、同じword_idxが連続している。最初のtoken以外は-100にする\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_train_dataset = labele2id_train_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f5_score(precision: float, recall: float, beta: int = 5):\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    # seqevalのmetrics関数を使用して、精度、再現率、F1スコア、正解率を計算\n",
    "    precision = results[\"overall_precision\"]\n",
    "    recall = results[\"overall_recall\"]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "        \"f5score\": f5_score(precision, recall),\n",
    "    }\n",
    "\n",
    "    # f1 = f1_score(true_labels, true_predictions)\n",
    "    # accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "    # return {\n",
    "    #     \"precision\": precision,\n",
    "    #     \"recall\": recall,\n",
    "    #     \"f1\": f1,\n",
    "    #     \"accuracy\": accuracy,\n",
    "    #     \"f5score\": f5_score(precision, recall),  # F5スコアを追加\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqeval = evaluate.load(\"seqeval\")\n",
    "# predictions = [\n",
    "#     [\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "#     [\"B-PER\", \"I-PER\", \"O\"],\n",
    "# ]\n",
    "# references = [\n",
    "#     [\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "#     [\"B-PER\", \"I-PER\", \"O\"],\n",
    "# ]\n",
    "# results = seqeval.compute(predictions=predictions, references=references)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[\"recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalデータの用意\n",
    "split_dataset = tokenized_train_dataset.train_test_split(test_size=0.2)\n",
    "tokenized_train_valid_dataset = DatasetDict(\n",
    "    {\"train\": split_dataset[\"train\"], \"valid\": split_dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=LOG_PATH,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,  # 32はだめ、性能がepoch0の時、precision0.31→0.00、Recall0.25→0.00に落ちる\n",
    "    per_device_eval_batch_size=16,  # 32,↑同様、バッチサイズが非常に重要なパラメーターであるとも言える\n",
    "    # num_train_epochs=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"f5score\",  # add\n",
    "    greater_is_better=True,  # add\n",
    "    warmup_ratio=0.1,  # add\n",
    "    lr_scheduler_type=\"cosine\",  # add\n",
    "    report_to=REPORT_TO,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_valid_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_train_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1023' max='1023' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1023/1023 04:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F5score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>0.057637</td>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.042407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.510373</td>\n",
       "      <td>0.572093</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.514644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.576763</td>\n",
       "      <td>0.617778</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.579724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# モデルの保存\n",
    "trainer.train()\n",
    "cv_score = trainer.evaluate()[\"eval_f5score\"]\n",
    "trainer.save_model(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make CV DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_preds(trainer, valid_dataset):\n",
    "    \"\"\"\n",
    "    trainerを用いてvalid_datasetに対する予測を行う\n",
    "    \"\"\"\n",
    "    predictions = trainer.predict(valid_dataset).predictions\n",
    "    preds_final = predictions.argmax(-1)\n",
    "\n",
    "    return preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer):\n",
    "    text = []\n",
    "    token_map = []\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n",
    "        text.append(t)\n",
    "        token_map.extend([idx] * len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            token_map.append(-1)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    # tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=INFERENCE_MAX_LENGTH)\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True)\n",
    "\n",
    "    return {\n",
    "        **tokenized,\n",
    "        \"token_map\": token_map,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_part(preds_final, valid_dataset):\n",
    "    triplets = []\n",
    "    document, token, label, token_str = [], [], [], []\n",
    "    for p, token_map, offsets, tokens, doc in zip(\n",
    "        preds_final,\n",
    "        valid_dataset[\"token_map\"],\n",
    "        valid_dataset[\"offset_mapping\"],\n",
    "        valid_dataset[\"tokens\"],\n",
    "        valid_dataset[\"document\"],\n",
    "    ):\n",
    "        for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "            label_pred = id2label[token_pred]\n",
    "\n",
    "            if start_idx + end_idx == 0:\n",
    "                continue\n",
    "\n",
    "            if token_map[start_idx] == -1:\n",
    "                start_idx += 1\n",
    "\n",
    "            # ignore \"\\n\\n\"\n",
    "            while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "                start_idx += 1\n",
    "\n",
    "            if start_idx >= len(token_map):\n",
    "                break\n",
    "\n",
    "            token_id = token_map[start_idx]\n",
    "\n",
    "            # ignore \"O\" predictions and whitespace preds\n",
    "            if label_pred != \"O\" and token_id != -1:\n",
    "                triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "                if triplet not in triplets:\n",
    "                    document.append(doc)\n",
    "                    token.append(token_id)\n",
    "                    label.append(label_pred)\n",
    "                    token_str.append(tokens[token_id])\n",
    "                    triplets.append(triplet)\n",
    "\n",
    "    return document, token, label, token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correct_df(train: pl.DataFrame):\n",
    "    # 学習データから、outputと同様のデータフレームを作成する\n",
    "    outputs = []\n",
    "    for document_id, token, label in zip(\n",
    "        train[\"document\"], train[\"tokens\"], train[\"labels\"]\n",
    "    ):\n",
    "        for token, (token_str, label_one) in enumerate(zip(token, label)):\n",
    "            if label_one != \"O\":\n",
    "                outputs.append((document_id, token, token_str, label_one))\n",
    "    return pl.DataFrame(outputs, schema=[\"document\", \"token\", \"label\", \"token_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correct_pred_join_df(\n",
    "    train_correct_df: pl.DataFrame, valid_pred_df: pl.DataFrame\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    validで利用したdocumentのみを抽出し、train_correct_dfとvalid_pred_dfを結合して、documentごとに比較できるようにする\n",
    "    \"\"\"\n",
    "    out = train_correct_df.filter(\n",
    "        pl.col(\"document\").is_in(valid_pred_df[\"document\"])\n",
    "    ).join(valid_pred_df, on=[\"document\", \"token\"], how=\"outer\", suffix=\"_pred\")\n",
    "\n",
    "    joined_dfs = []\n",
    "    for document in out[\"document\"].unique().to_list():\n",
    "        if document is None:\n",
    "            continue\n",
    "        joined_df_per_document = out.filter(\n",
    "            (pl.col(\"document\") == document) | (pl.col(\"document_pred\") == document)\n",
    "        )\n",
    "        joined_dfs.append(joined_df_per_document)\n",
    "\n",
    "    return pl.concat(joined_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd5f440b8054480a8c49941ec265eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1362 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# main\n",
    "valid_dataset = tokenized_train_valid_dataset[\"valid\"]\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize, fn_kwargs={\"tokenizer\": tokenizer}, num_proc=2\n",
    ")\n",
    "\n",
    "valid_preds = get_valid_preds(trainer, valid_dataset)\n",
    "\n",
    "document, token, label, token_str = get_output_part(valid_preds, valid_dataset)\n",
    "\n",
    "valid_pred_df = pl.DataFrame(\n",
    "    [document, token, label, token_str],\n",
    "    schema=[\"document\", \"token\", \"label\", \"token_str\"],\n",
    ")\n",
    "\n",
    "train_correct_df = make_correct_df(train)\n",
    "\n",
    "# wandbにuploadする\n",
    "valid_correct_pred_df = make_correct_pred_join_df(train_correct_df, valid_pred_df)\n",
    "tbl = wandb.Table(data=valid_correct_pred_df.to_pandas())\n",
    "wandb.log({\"valid_correct_pred_df\": tbl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (462, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>token</th><th>label</th><th>token_str</th><th>document_pred</th><th>token_pred</th><th>label_pred</th><th>token_str_pred</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>123</td><td>32</td><td>&quot;Stefano&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>123</td><td>32</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Stefano&quot;</td></tr><tr><td>123</td><td>33</td><td>&quot;Lovato&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>123</td><td>33</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Lovato&quot;</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>123</td><td>35</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;MDI-191&quot;</td></tr><tr><td>330</td><td>18</td><td>&quot;Davide&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>330</td><td>18</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Davide&quot;</td></tr><tr><td>330</td><td>19</td><td>&quot;Carletti&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>330</td><td>19</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Carletti&quot;</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>330</td><td>24</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Marias&quot;</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>330</td><td>316</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Marias&quot;</td></tr><tr><td>333</td><td>20</td><td>&quot;Karan&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>333</td><td>20</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Karan&quot;</td></tr><tr><td>333</td><td>21</td><td>&quot;Patel&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>333</td><td>21</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Patel&quot;</td></tr><tr><td>344</td><td>7</td><td>&quot;Milton&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>344</td><td>7</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Milton&quot;</td></tr><tr><td>344</td><td>8</td><td>&quot;Desai&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>344</td><td>8</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Desai&quot;</td></tr><tr><td>730</td><td>3</td><td>&quot;Ahmed&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>730</td><td>3</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Ahmed&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>12899</td><td>2</td><td>&quot;Angelo&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>12899</td><td>2</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Angelo&quot;</td></tr><tr><td>12899</td><td>3</td><td>&quot;Adamo&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>12899</td><td>3</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Adamo&quot;</td></tr><tr><td>12962</td><td>3</td><td>&quot;Brittany&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>12962</td><td>3</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Brittany&quot;</td></tr><tr><td>12962</td><td>4</td><td>&quot;Robinson&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>12962</td><td>4</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Robinson&quot;</td></tr><tr><td>13047</td><td>4</td><td>&quot;Matteo&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>13047</td><td>4</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Matteo&quot;</td></tr><tr><td>13047</td><td>5</td><td>&quot;Sanna&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>13047</td><td>5</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Sanna&quot;</td></tr><tr><td>13066</td><td>5</td><td>&quot;Mirian&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>13066</td><td>5</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Mirian&quot;</td></tr><tr><td>13066</td><td>6</td><td>&quot;Obrien&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>13066</td><td>6</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Obrien&quot;</td></tr><tr><td>13158</td><td>6</td><td>&quot;Adem&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>13158</td><td>6</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Adem&quot;</td></tr><tr><td>13158</td><td>7</td><td>&quot;Moka&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>13158</td><td>7</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Moka&quot;</td></tr><tr><td>13223</td><td>0</td><td>&quot;Erika&quot;</td><td>&quot;B-NAME_STUDENT…</td><td>13223</td><td>0</td><td>&quot;B-NAME_STUDENT…</td><td>&quot;Erika&quot;</td></tr><tr><td>13223</td><td>1</td><td>&quot;Taborda&quot;</td><td>&quot;I-NAME_STUDENT…</td><td>13223</td><td>1</td><td>&quot;I-NAME_STUDENT…</td><td>&quot;Taborda&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (462, 8)\n",
       "┌──────────┬───────┬──────────┬─────────────┬─────────────┬────────────┬─────────────┬─────────────┐\n",
       "│ document ┆ token ┆ label    ┆ token_str   ┆ document_pr ┆ token_pred ┆ label_pred  ┆ token_str_p │\n",
       "│ ---      ┆ ---   ┆ ---      ┆ ---         ┆ ed          ┆ ---        ┆ ---         ┆ red         │\n",
       "│ i64      ┆ i64   ┆ str      ┆ str         ┆ ---         ┆ i64        ┆ str         ┆ ---         │\n",
       "│          ┆       ┆          ┆             ┆ i64         ┆            ┆             ┆ str         │\n",
       "╞══════════╪═══════╪══════════╪═════════════╪═════════════╪════════════╪═════════════╪═════════════╡\n",
       "│ 123      ┆ 32    ┆ Stefano  ┆ B-NAME_STUD ┆ 123         ┆ 32         ┆ B-NAME_STUD ┆ Stefano     │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 123      ┆ 33    ┆ Lovato   ┆ I-NAME_STUD ┆ 123         ┆ 33         ┆ I-NAME_STUD ┆ Lovato      │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ null     ┆ null  ┆ null     ┆ null        ┆ 123         ┆ 35         ┆ I-NAME_STUD ┆ MDI-191     │\n",
       "│          ┆       ┆          ┆             ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 330      ┆ 18    ┆ Davide   ┆ B-NAME_STUD ┆ 330         ┆ 18         ┆ B-NAME_STUD ┆ Davide      │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 330      ┆ 19    ┆ Carletti ┆ I-NAME_STUD ┆ 330         ┆ 19         ┆ B-NAME_STUD ┆ Carletti    │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ …        ┆ …     ┆ …        ┆ …           ┆ …           ┆ …          ┆ …           ┆ …           │\n",
       "│ 13066    ┆ 6     ┆ Obrien   ┆ I-NAME_STUD ┆ 13066       ┆ 6          ┆ I-NAME_STUD ┆ Obrien      │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 13158    ┆ 6     ┆ Adem     ┆ B-NAME_STUD ┆ 13158       ┆ 6          ┆ B-NAME_STUD ┆ Adem        │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 13158    ┆ 7     ┆ Moka     ┆ I-NAME_STUD ┆ 13158       ┆ 7          ┆ I-NAME_STUD ┆ Moka        │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 13223    ┆ 0     ┆ Erika    ┆ B-NAME_STUD ┆ 13223       ┆ 0          ┆ B-NAME_STUD ┆ Erika       │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "│ 13223    ┆ 1     ┆ Taborda  ┆ I-NAME_STUD ┆ 13223       ┆ 1          ┆ I-NAME_STUD ┆ Taborda     │\n",
       "│          ┆       ┆          ┆ ENT         ┆             ┆            ┆ ENT         ┆             │\n",
       "└──────────┴───────┴──────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_correct_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(\"cp /notebooks/pll_data_detection/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:e02-make-val-out-distilbert-base-uncased, output_dir:pll_data_detection/trained_models/e02-make-val-out\n",
      "Starting upload for file training_args.bin\n",
      "Upload successful: training_args.bin (4KB)\n",
      "Starting upload for file vocab.txt\n",
      "Upload successful: vocab.txt (226KB)\n",
      "Starting upload for file tokenizer.json\n",
      "Upload successful: tokenizer.json (695KB)\n",
      "Starting upload for file config.json\n",
      "Upload successful: config.json (1KB)\n",
      "Starting upload for file tokenizer_config.json\n",
      "Upload successful: tokenizer_config.json (1KB)\n",
      "Starting upload for file model.safetensors\n",
      "Upload successful: model.safetensors (253MB)\n",
      "Starting upload for file special_tokens_map.json\n",
      "Upload successful: special_tokens_map.json (125B)\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    if \"_\" in dataset_name:\n",
    "        raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "    dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "    dataset_metadata[\"title\"] = dataset_name\n",
    "    with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "\n",
    "if (not DEBUG) and UPLOAD_DATA:\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
