{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/pll_data_detection/exp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"exp001\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "LOG_PATH = f\"pll_data_detection/log/{EXP_NAME}\"\n",
    "MODEL_OUTPUT_PATH = f\"pll_data_detection/trained_models/{EXP_NAME}\"\n",
    "SUB_OUTPUT_PATH = f\"pll_data_detection/submissions/{EXP_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6346.12s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.16.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (18.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polars\n",
      "  Downloading polars-0.20.6-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.8/26.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: polars\n",
      "Successfully installed polars-0.20.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (18.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting datasets==2.16.1\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (4.64.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (3.9.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (1.5.0)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (2023.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (5.4.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (3.2.0)\n",
      "Collecting huggingface-hub>=0.19.4\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (10.0.1)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (1.23.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets==2.16.1) (3.8.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (18.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.16.1) (1.3.3)\n",
      "Collecting huggingface-hub>=0.19.4\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading huggingface_hub-0.20.0-py3-none-any.whl (329 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of aiohttp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.16.1) (1.26.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.16.1) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.16.1) (1.14.0)\n",
      "Installing collected packages: pyarrow-hotfix, fsspec, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "Successfully installed datasets-2.16.1 fsspec-2023.10.0 huggingface-hub-0.20.3 pyarrow-hotfix-0.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.9.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=b0ad513ea70ea293b0dd1d209fecc31b0f6ec0e1657399f530ecd7ba90ba11fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/9c/d6/00/1ccfd5a7466a94774e00022683d4b028836032dfb85007822b\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.23.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.16.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (18.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting black\n",
      "  Downloading black-24.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting isort\n",
      "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from black) (2.0.1)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from black) (8.1.3)\n",
      "Collecting pathspec>=0.9.0\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from black) (4.4.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.9/dist-packages (from black) (2.6.2)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.9/dist-packages (from black) (23.0)\n",
      "Installing collected packages: pathspec, mypy-extensions, isort, black\n",
      "Successfully installed black-24.1.1 isort-5.13.2 mypy-extensions-1.0.0 pathspec-0.12.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install polars\n",
    "%pip install transformers==4.37.2\n",
    "%pip install datasets==2.16.1\n",
    "%pip install evaluate==0.4.1\n",
    "%pip install seqeval==1.2.2\n",
    "\n",
    "# formatter\n",
    "%pip install black isort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TokenClassificationPipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.21.3'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "datasets.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seqeval' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [138], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseqeval\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mseqeval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seqeval' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import seqeval\n",
    "\n",
    "seqeval.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  4 00:42:34 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 26%   30C    P8     6W / 180W |      2MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>full_text</th><th>tokens</th><th>trailing_whitespace</th><th>labels</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[bool]</td><td>list[str]</td></tr></thead><tbody><tr><td>7</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>10</td><td>&quot;Diego Estrada\n",
       "…</td><td>[&quot;Diego&quot;, &quot;Estrada&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;B-NAME_STUDENT&quot;, &quot;I-NAME_STUDENT&quot;, … &quot;O&quot;]</td></tr><tr><td>16</td><td>&quot;Reporting proc…</td><td>[&quot;Reporting&quot;, &quot;process&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>20</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr><tr><td>56</td><td>&quot;Assignment:  V…</td><td>[&quot;Assignment&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td><td>[&quot;O&quot;, &quot;O&quot;, … &quot;O&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────┬─────────────────────┬─────────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ document ┆ full_text           ┆ tokens              ┆ trailing_whitespace ┆ labels              │\n",
       "│ ---      ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---                 │\n",
       "│ i64      ┆ str                 ┆ list[str]           ┆ list[bool]          ┆ list[str]           │\n",
       "╞══════════╪═════════════════════╪═════════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 7        ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ innovation r…       ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 10       ┆ Diego Estrada       ┆ [\"Diego\",           ┆ [true, false, …     ┆ [\"B-NAME_STUDENT\",  │\n",
       "│          ┆                     ┆ \"Estrada\", … \"      ┆ false]              ┆ \"I-NAME_STUDE…      │\n",
       "│          ┆ Design Thinking A…  ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 16       ┆ Reporting process   ┆ [\"Reporting\",       ┆ [true, false, …     ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆                     ┆ \"process\", … \"      ┆ false]              ┆                     │\n",
       "│          ┆ by Gilberto G…      ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "│ 20       ┆ Design Thinking for ┆ [\"Design\",          ┆ [true, true, …      ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ Innovation          ┆ \"Thinking\", … \"     ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆ …                   ┆ \"]                  ┆                     ┆                     │\n",
       "│ 56       ┆ Assignment:  Visual ┆ [\"Assignment\", \":\", ┆ [false, false, …    ┆ [\"O\", \"O\", … \"O\"]   │\n",
       "│          ┆ ization Refle…      ┆ … \"                 ┆ false]              ┆                     │\n",
       "│          ┆                     ┆                     ┆                     ┆                     │\n",
       "│          ┆                     ┆ \"]                  ┆                     ┆                     │\n",
       "└──────────┴─────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ確認用\n",
    "train = pl.read_json(\"pll_data_detection/train.json\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>full_text</th><th>tokens</th><th>trailing_whitespace</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[bool]</td></tr></thead><tbody><tr><td>7</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>10</td><td>&quot;Diego Estrada\n",
       "…</td><td>[&quot;Diego&quot;, &quot;Estrada&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>16</td><td>&quot;Reporting proc…</td><td>[&quot;Reporting&quot;, &quot;process&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>20</td><td>&quot;Design Thinkin…</td><td>[&quot;Design&quot;, &quot;Thinking&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>56</td><td>&quot;Assignment:  V…</td><td>[&quot;Assignment&quot;, &quot;:&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[false, false, … false]</td></tr><tr><td>86</td><td>&quot;Cheese Startup…</td><td>[&quot;Cheese&quot;, &quot;Startup&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>93</td><td>&quot;Silvia Villalo…</td><td>[&quot;Silvia&quot;, &quot;Villalobos&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>104</td><td>&quot;Storytelling  …</td><td>[&quot;Storytelling&quot;, &quot; &quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, false, … false]</td></tr><tr><td>112</td><td>&quot;Reflection – L…</td><td>[&quot;Reflection&quot;, &quot;–&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr><tr><td>123</td><td>&quot;Gandhi Institu…</td><td>[&quot;Gandhi&quot;, &quot;Institute&quot;, … &quot;\n",
       "\n",
       "&quot;]</td><td>[true, true, … false]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌──────────┬──────────────────────────────┬──────────────────────────────┬─────────────────────────┐\n",
       "│ document ┆ full_text                    ┆ tokens                       ┆ trailing_whitespace     │\n",
       "│ ---      ┆ ---                          ┆ ---                          ┆ ---                     │\n",
       "│ i64      ┆ str                          ┆ list[str]                    ┆ list[bool]              │\n",
       "╞══════════╪══════════════════════════════╪══════════════════════════════╪═════════════════════════╡\n",
       "│ 7        ┆ Design Thinking for          ┆ [\"Design\", \"Thinking\", … \"   ┆ [true, true, … false]   │\n",
       "│          ┆ innovation r…                ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 10       ┆ Diego Estrada                ┆ [\"Diego\", \"Estrada\", … \"     ┆ [true, false, … false]  │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ Design Thinking A…           ┆ \"]                           ┆                         │\n",
       "│ 16       ┆ Reporting process            ┆ [\"Reporting\", \"process\", … \" ┆ [true, false, … false]  │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ by Gilberto G…               ┆ \"]                           ┆                         │\n",
       "│ 20       ┆ Design Thinking for          ┆ [\"Design\", \"Thinking\", … \"   ┆ [true, true, … false]   │\n",
       "│          ┆ Innovation                   ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│          ┆ …                            ┆                              ┆                         │\n",
       "│ 56       ┆ Assignment:                  ┆ [\"Assignment\", \":\", … \"      ┆ [false, false, … false] │\n",
       "│          ┆ Visualization Refle…         ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 86       ┆ Cheese Startup - Learning    ┆ [\"Cheese\", \"Startup\", … \"    ┆ [true, true, … false]   │\n",
       "│          ┆ Launch…                      ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 93       ┆ Silvia Villalobos            ┆ [\"Silvia\", \"Villalobos\", … \" ┆ [true, false, … false]  │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ Challenge:                   ┆ \"]                           ┆                         │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ T…                           ┆                              ┆                         │\n",
       "│ 104      ┆ Storytelling  The Path to    ┆ [\"Storytelling\", \" \", … \"    ┆ [true, false, … false]  │\n",
       "│          ┆ Innova…                      ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "│ 112      ┆ Reflection – Learning Launch ┆ [\"Reflection\", \"–\", … \"      ┆ [true, true, … false]   │\n",
       "│          ┆                              ┆                              ┆                         │\n",
       "│          ┆ Fr…                          ┆ \"]                           ┆                         │\n",
       "│ 123      ┆ Gandhi Institute of          ┆ [\"Gandhi\", \"Institute\", … \"  ┆ [true, true, … false]   │\n",
       "│          ┆ Technology a…                ┆                              ┆                         │\n",
       "│          ┆                              ┆ \"]                           ┆                         │\n",
       "└──────────┴──────────────────────────────┴──────────────────────────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ確認用\n",
    "test = pl.read_json(\"pll_data_detection/test.json\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8b1e4e46444926a4f07909d0317de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba64fa5ba78d431eb5596c4c2ccca810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"json\", data_files={\"train\": \"pll_data_detection/train.json\"}, split=\"train\"\n",
    ")\n",
    "test_dataset = load_dataset(\n",
    "    \"json\", data_files={\"test\": \"pll_data_detection/test.json\"}, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "train_dataset = train_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980d9450f55a47e18075714be439bcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f6bbe1ba6b49f7aa213b5f44fa5d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c96afb88eb4ca39c2e873926d9036c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f5627524b6413db9c4496baa8cb3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'design',\n",
       " 'thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflex',\n",
       " '##ion',\n",
       " '-',\n",
       " 'av',\n",
       " '##ril',\n",
       " '2021',\n",
       " '-',\n",
       " 'nat',\n",
       " '##hal',\n",
       " '##ie',\n",
       " 'sy',\n",
       " '##lla',\n",
       " 'challenge',\n",
       " '&',\n",
       " 'selection',\n",
       " 'the',\n",
       " 'tool',\n",
       " 'i',\n",
       " 'use',\n",
       " 'to',\n",
       " 'help',\n",
       " 'all',\n",
       " 'stakeholders',\n",
       " 'finding',\n",
       " 'their',\n",
       " 'way',\n",
       " 'through',\n",
       " 'the',\n",
       " 'complexity',\n",
       " 'of',\n",
       " 'a',\n",
       " 'project',\n",
       " 'is',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " '.',\n",
       " 'what',\n",
       " 'exactly',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'map',\n",
       " '?',\n",
       " 'according',\n",
       " 'to',\n",
       " 'the',\n",
       " 'definition',\n",
       " 'of',\n",
       " 'bu',\n",
       " '##zan',\n",
       " 't',\n",
       " '.',\n",
       " 'and',\n",
       " 'bu',\n",
       " '##zan',\n",
       " 'b',\n",
       " '.',\n",
       " '(',\n",
       " '1999',\n",
       " ',',\n",
       " 'des',\n",
       " '##sin',\n",
       " '##e',\n",
       " '-',\n",
       " 'moi',\n",
       " 'l',\n",
       " \"'\",\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'paris',\n",
       " ':',\n",
       " 'les',\n",
       " 'editions',\n",
       " 'd',\n",
       " \"'\",\n",
       " 'organisation',\n",
       " '.',\n",
       " ')',\n",
       " ',',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " '(',\n",
       " 'or',\n",
       " 'he',\n",
       " '##uri',\n",
       " '##stic',\n",
       " 'diagram',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'graphic',\n",
       " 'representation',\n",
       " 'technique',\n",
       " 'that',\n",
       " 'follows',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'functioning',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'and',\n",
       " 'allows',\n",
       " 'the',\n",
       " 'brain',\n",
       " \"'\",\n",
       " 's',\n",
       " 'potential',\n",
       " 'to',\n",
       " 'be',\n",
       " 'released',\n",
       " '.',\n",
       " 'cf',\n",
       " 'annex',\n",
       " '##1',\n",
       " 'this',\n",
       " 'tool',\n",
       " 'has',\n",
       " 'many',\n",
       " 'advantages',\n",
       " ':',\n",
       " '•',\n",
       " 'it',\n",
       " 'is',\n",
       " 'accessible',\n",
       " 'to',\n",
       " 'all',\n",
       " 'and',\n",
       " 'does',\n",
       " 'not',\n",
       " 'require',\n",
       " 'significant',\n",
       " 'material',\n",
       " 'investment',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " 'quickly',\n",
       " '•',\n",
       " 'it',\n",
       " 'is',\n",
       " 'scala',\n",
       " '##ble',\n",
       " '•',\n",
       " 'it',\n",
       " 'allows',\n",
       " 'cat',\n",
       " '##ego',\n",
       " '##rization',\n",
       " 'and',\n",
       " 'linking',\n",
       " 'of',\n",
       " 'information',\n",
       " '•',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'applied',\n",
       " 'to',\n",
       " 'any',\n",
       " 'type',\n",
       " 'of',\n",
       " 'situation',\n",
       " ':',\n",
       " 'note',\n",
       " '##taking',\n",
       " ',',\n",
       " 'problem',\n",
       " 'solving',\n",
       " ',',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'new',\n",
       " 'ideas',\n",
       " '•',\n",
       " 'it',\n",
       " 'is',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'all',\n",
       " 'people',\n",
       " 'and',\n",
       " 'is',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'learn',\n",
       " '•',\n",
       " 'it',\n",
       " 'is',\n",
       " 'fun',\n",
       " 'and',\n",
       " 'encourages',\n",
       " 'exchanges',\n",
       " '•',\n",
       " 'it',\n",
       " 'makes',\n",
       " 'visible',\n",
       " 'the',\n",
       " 'dimension',\n",
       " 'of',\n",
       " 'projects',\n",
       " ',',\n",
       " 'opportunities',\n",
       " ',',\n",
       " 'inter',\n",
       " '##con',\n",
       " '##ne',\n",
       " '##ctions',\n",
       " '•',\n",
       " 'it',\n",
       " 'synth',\n",
       " '##es',\n",
       " '##izes',\n",
       " '•',\n",
       " 'it',\n",
       " 'makes',\n",
       " 'the',\n",
       " 'project',\n",
       " 'understand',\n",
       " '##able',\n",
       " '•',\n",
       " 'it',\n",
       " 'allows',\n",
       " 'you',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'ideas',\n",
       " 'the',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'map',\n",
       " 'starts',\n",
       " 'with',\n",
       " 'an',\n",
       " 'idea',\n",
       " '/',\n",
       " 'problem',\n",
       " 'located',\n",
       " 'at',\n",
       " 'its',\n",
       " 'center',\n",
       " '.',\n",
       " 'this',\n",
       " 'starting',\n",
       " 'point',\n",
       " 'generates',\n",
       " 'ideas',\n",
       " '/',\n",
       " 'work',\n",
       " 'areas',\n",
       " ',',\n",
       " 'inc',\n",
       " '##rem',\n",
       " '##ented',\n",
       " 'around',\n",
       " 'this',\n",
       " 'center',\n",
       " 'in',\n",
       " 'a',\n",
       " 'radial',\n",
       " 'structure',\n",
       " ',',\n",
       " 'which',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'is',\n",
       " 'completed',\n",
       " 'with',\n",
       " 'as',\n",
       " 'many',\n",
       " 'branches',\n",
       " 'as',\n",
       " 'new',\n",
       " 'ideas',\n",
       " '.',\n",
       " 'this',\n",
       " 'tool',\n",
       " 'enables',\n",
       " 'creativity',\n",
       " 'and',\n",
       " 'logic',\n",
       " 'to',\n",
       " 'be',\n",
       " 'mobilized',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'map',\n",
       " 'of',\n",
       " 'the',\n",
       " 'thoughts',\n",
       " '.',\n",
       " 'creativity',\n",
       " 'is',\n",
       " 'enhanced',\n",
       " 'because',\n",
       " 'participants',\n",
       " 'feel',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'the',\n",
       " 'method',\n",
       " '.',\n",
       " 'application',\n",
       " '&',\n",
       " 'insight',\n",
       " 'i',\n",
       " 'start',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " 'creation',\n",
       " 'with',\n",
       " 'the',\n",
       " 'stakeholders',\n",
       " 'standing',\n",
       " 'around',\n",
       " 'a',\n",
       " 'large',\n",
       " 'board',\n",
       " '(',\n",
       " 'white',\n",
       " 'or',\n",
       " 'paper',\n",
       " 'board',\n",
       " ')',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'center',\n",
       " 'of',\n",
       " 'the',\n",
       " 'board',\n",
       " ',',\n",
       " 'i',\n",
       " 'write',\n",
       " 'and',\n",
       " 'highlight',\n",
       " 'the',\n",
       " 'topic',\n",
       " 'to',\n",
       " 'design',\n",
       " '.',\n",
       " 'through',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'questions',\n",
       " ',',\n",
       " 'i',\n",
       " 'guide',\n",
       " 'the',\n",
       " 'stakeholders',\n",
       " 'in',\n",
       " 'modelling',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " '.',\n",
       " 'i',\n",
       " 'adapt',\n",
       " 'the',\n",
       " 'series',\n",
       " 'of',\n",
       " 'questions',\n",
       " 'according',\n",
       " 'to',\n",
       " 'the',\n",
       " 'topic',\n",
       " 'to',\n",
       " 'be',\n",
       " 'addressed',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'type',\n",
       " 'of',\n",
       " 'questions',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'use',\n",
       " ':',\n",
       " 'who',\n",
       " ',',\n",
       " 'what',\n",
       " ',',\n",
       " 'when',\n",
       " ',',\n",
       " 'where',\n",
       " ',',\n",
       " 'why',\n",
       " ',',\n",
       " 'how',\n",
       " ',',\n",
       " 'how',\n",
       " 'much',\n",
       " '.',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " '“',\n",
       " 'why',\n",
       " '”',\n",
       " 'is',\n",
       " 'very',\n",
       " 'interesting',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'the',\n",
       " 'origin',\n",
       " '.',\n",
       " 'by',\n",
       " 'this',\n",
       " 'way',\n",
       " ',',\n",
       " 'the',\n",
       " 'interviewed',\n",
       " 'person',\n",
       " 'free',\n",
       " '##s',\n",
       " 'itself',\n",
       " 'from',\n",
       " 'paradigm',\n",
       " '##s',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'dare',\n",
       " '##s',\n",
       " 'to',\n",
       " 'propose',\n",
       " 'new',\n",
       " 'ideas',\n",
       " '/',\n",
       " 'ways',\n",
       " 'of',\n",
       " 'functioning',\n",
       " '.',\n",
       " 'i',\n",
       " 'plan',\n",
       " 'two',\n",
       " 'hours',\n",
       " 'for',\n",
       " 'a',\n",
       " 'workshop',\n",
       " '.',\n",
       " 'design',\n",
       " 'thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflex',\n",
       " '##ion',\n",
       " '-',\n",
       " 'av',\n",
       " '##ril',\n",
       " '2021',\n",
       " '-',\n",
       " 'nat',\n",
       " '##hal',\n",
       " '##ie',\n",
       " 'sy',\n",
       " '##lla',\n",
       " 'after',\n",
       " 'modelling',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " 'on',\n",
       " 'paper',\n",
       " ',',\n",
       " 'i',\n",
       " 'propose',\n",
       " 'to',\n",
       " 'the',\n",
       " 'participants',\n",
       " 'a',\n",
       " 'digital',\n",
       " 'visual',\n",
       " '##ization',\n",
       " 'of',\n",
       " 'their',\n",
       " 'work',\n",
       " 'with',\n",
       " 'the',\n",
       " 'addition',\n",
       " 'of',\n",
       " 'color',\n",
       " 'codes',\n",
       " ',',\n",
       " 'images',\n",
       " 'and',\n",
       " 'inter',\n",
       " '##con',\n",
       " '##ne',\n",
       " '##ctions',\n",
       " '.',\n",
       " 'this',\n",
       " 'second',\n",
       " 'workshop',\n",
       " 'also',\n",
       " 'lasts',\n",
       " 'two',\n",
       " 'hours',\n",
       " 'and',\n",
       " 'allows',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " 'to',\n",
       " 'evolve',\n",
       " '.',\n",
       " 'once',\n",
       " 'familiar',\n",
       " '##ized',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'the',\n",
       " 'stakeholders',\n",
       " 'discover',\n",
       " 'the',\n",
       " 'power',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tool',\n",
       " '.',\n",
       " 'then',\n",
       " ',',\n",
       " 'the',\n",
       " 'second',\n",
       " 'workshop',\n",
       " 'brings',\n",
       " 'out',\n",
       " 'even',\n",
       " 'more',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'constructive',\n",
       " 'exchanges',\n",
       " 'between',\n",
       " 'the',\n",
       " 'stakeholders',\n",
       " '.',\n",
       " 'around',\n",
       " 'this',\n",
       " 'new',\n",
       " 'mind',\n",
       " 'map',\n",
       " ',',\n",
       " 'they',\n",
       " 'have',\n",
       " 'learned',\n",
       " 'to',\n",
       " 'work',\n",
       " 'together',\n",
       " 'and',\n",
       " 'want',\n",
       " 'to',\n",
       " 'make',\n",
       " 'visible',\n",
       " 'the',\n",
       " 'unto',\n",
       " '##ld',\n",
       " 'ideas',\n",
       " '.',\n",
       " 'i',\n",
       " 'now',\n",
       " 'present',\n",
       " 'all',\n",
       " 'the',\n",
       " 'projects',\n",
       " 'i',\n",
       " 'manage',\n",
       " 'in',\n",
       " 'this',\n",
       " 'type',\n",
       " 'of',\n",
       " 'format',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'ease',\n",
       " 'rapid',\n",
       " 'understanding',\n",
       " 'for',\n",
       " 'decision',\n",
       " '-',\n",
       " 'makers',\n",
       " '.',\n",
       " 'these',\n",
       " 'presentations',\n",
       " 'are',\n",
       " 'the',\n",
       " 'core',\n",
       " 'of',\n",
       " 'my',\n",
       " 'business',\n",
       " 'models',\n",
       " '.',\n",
       " 'the',\n",
       " 'decision',\n",
       " '-',\n",
       " 'makers',\n",
       " 'are',\n",
       " 'thus',\n",
       " 'able',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'the',\n",
       " 'opportunities',\n",
       " 'of',\n",
       " 'the',\n",
       " 'projects',\n",
       " 'and',\n",
       " 'can',\n",
       " 'take',\n",
       " 'quick',\n",
       " 'decisions',\n",
       " 'to',\n",
       " 'valid',\n",
       " '##ate',\n",
       " 'them',\n",
       " '.',\n",
       " 'they',\n",
       " 'find',\n",
       " 'answers',\n",
       " 'to',\n",
       " 'their',\n",
       " 'questions',\n",
       " 'thank',\n",
       " 'to',\n",
       " 'a',\n",
       " 'sc',\n",
       " '##hema',\n",
       " '##tic',\n",
       " 'representation',\n",
       " '.',\n",
       " 'approach',\n",
       " 'what',\n",
       " 'i',\n",
       " 'find',\n",
       " 'amazing',\n",
       " 'with',\n",
       " 'the',\n",
       " 'fa',\n",
       " '##ci',\n",
       " '##lita',\n",
       " '##tion',\n",
       " 'of',\n",
       " 'this',\n",
       " 'type',\n",
       " 'of',\n",
       " 'workshop',\n",
       " 'is',\n",
       " 'the',\n",
       " 'participants',\n",
       " 'commitment',\n",
       " 'for',\n",
       " 'the',\n",
       " 'project',\n",
       " '.',\n",
       " 'this',\n",
       " 'tool',\n",
       " 'helps',\n",
       " 'to',\n",
       " 'give',\n",
       " 'meaning',\n",
       " '.',\n",
       " 'the',\n",
       " 'participants',\n",
       " 'appropriate',\n",
       " 'the',\n",
       " 'story',\n",
       " 'and',\n",
       " 'want',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'writing',\n",
       " 'it',\n",
       " '.',\n",
       " 'then',\n",
       " ',',\n",
       " 'they',\n",
       " 'easily',\n",
       " 'become',\n",
       " 'actors',\n",
       " 'or',\n",
       " 'sponsors',\n",
       " 'of',\n",
       " 'the',\n",
       " 'project',\n",
       " '.',\n",
       " 'a',\n",
       " 'trust',\n",
       " 'relationship',\n",
       " 'is',\n",
       " 'built',\n",
       " ',',\n",
       " 'thus',\n",
       " 'facilitating',\n",
       " 'the',\n",
       " 'implementation',\n",
       " 'of',\n",
       " 'related',\n",
       " 'actions',\n",
       " '.',\n",
       " 'design',\n",
       " 'thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflex',\n",
       " '##ion',\n",
       " '-',\n",
       " 'av',\n",
       " '##ril',\n",
       " '2021',\n",
       " '-',\n",
       " 'nat',\n",
       " '##hal',\n",
       " '##ie',\n",
       " 'sy',\n",
       " '##lla',\n",
       " 'annex',\n",
       " '1',\n",
       " ':',\n",
       " 'mind',\n",
       " 'map',\n",
       " 'shared',\n",
       " 'facilities',\n",
       " 'project',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: 512?が上限であるのに対し、NER対象のテキストが512よりも長い場合が多いため、適したモデルにする\n",
    "# DeBERTaあたりは、512を超えるテキストに対応していたような\n",
    "example = train_dataset[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ad957e71b54985be0515b8967c4b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# labelを変換する\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-NAME_STUDENT\",\n",
    "    2: \"I-NAME_STUDENT\",\n",
    "    3: \"B-EMAIL\",\n",
    "    4: \"I-EMAIL\",\n",
    "    5: \"B-USERNAME\",\n",
    "    6: \"I-USERNAME\",\n",
    "    7: \"B-ID_NUM\",\n",
    "    8: \"I-ID_NUM\",\n",
    "    9: \"B-PHONE_NUM\",\n",
    "    10: \"I-PHONE_NUM\",\n",
    "    11: \"B-URL_PERSONAL\",\n",
    "    12: \"I-URL_PERSONAL\",\n",
    "    13: \"B-STREET_ADDRESS\",\n",
    "    14: \"I-STREET_ADDRESS\",\n",
    "}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "def label2id_func(example):\n",
    "    example[\"labels\"] = [label2id[tag] for tag in example[\"labels\"]]\n",
    "    return example\n",
    "\n",
    "\n",
    "labele2id_train_dataset = train_dataset.map(label2id_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-NAME_STUDENT',\n",
       " 'I-NAME_STUDENT',\n",
       " 'B-EMAIL',\n",
       " 'I-EMAIL',\n",
       " 'B-USERNAME',\n",
       " 'I-USERNAME',\n",
       " 'B-ID_NUM',\n",
       " 'I-ID_NUM',\n",
       " 'B-PHONE_NUM',\n",
       " 'I-PHONE_NUM',\n",
       " 'B-URL_PERSONAL',\n",
       " 'I-URL_PERSONAL',\n",
       " 'B-STREET_ADDRESS',\n",
       " 'I-STREET_ADDRESS']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = list(label2id.keys())\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0ced7c0c874c6b96ba7de2f36b6af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        # トークン化されたシーケンス内の各トークンが元のテキスト内のどの単語に対応するかを示すIDを提供します。\n",
    "        # 例えば、元のテキストが \"Hello, world!\" で、トークン化されたシーケンスが [\"Hello\", \",\", \"world\", \"!\"] の場合\n",
    "        # `word_ids`メソッドは [0, None, 1, None] を返します。\n",
    "        # これは、\"Hello\" が最初の単語（インデックス0）、\",\" が単語に属さない（None）、\"world\" が2番目の単語（インデックス1）、\"!\" が単語に属さない（None）ことを示します。\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif (\n",
    "                word_idx != previous_word_idx\n",
    "            ):  # subwordの場合、同じword_idxが連続している。最初のtoken以外は-100にする\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_train_dataset = labele2id_train_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1306e3e8eaa544fa8bb3ad7b30c92db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd98530e6914a1f94c8a00528ab7467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalデータの用意\n",
    "tokenized_train_valid_dataset = tokenized_train_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=LOG_PATH,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_valid_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_train_valid_dataset[\"test\"],  # 名前はtestだが、実際はvalid\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "# trainer.train()\n",
    "# trainer.save_model(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subword(results):\n",
    "    # サブワードを結合\n",
    "    combined_results = []\n",
    "    current_entity = None\n",
    "    for result in results:\n",
    "        if result[\"word\"].startswith(\"##\"):\n",
    "            # サブワードの場合、現在のエンティティに追加\n",
    "            if current_entity is not None:\n",
    "                current_entity[\"word\"] += result[\"word\"][2:]\n",
    "                current_entity[\"end\"] = result[\"end\"]\n",
    "                current_entity[\"score\"] = (\n",
    "                    current_entity[\"score\"] + result[\"score\"]\n",
    "                ) / 2\n",
    "        else:\n",
    "            # 新しいエンティティの場合、現在のエンティティを結果に追加\n",
    "            if current_entity is not None:\n",
    "                combined_results.append(current_entity)\n",
    "            current_entity = result\n",
    "\n",
    "    # 最後のエンティティを結果に追加\n",
    "    if current_entity is not None:\n",
    "        combined_results.append(current_entity)\n",
    "\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file pll_data_detection/trained_models/exp001/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"pll_data_detection/trained_models/exp001\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-NAME_STUDENT\",\n",
      "    \"2\": \"I-NAME_STUDENT\",\n",
      "    \"3\": \"B-EMAIL\",\n",
      "    \"4\": \"I-EMAIL\",\n",
      "    \"5\": \"B-USERNAME\",\n",
      "    \"6\": \"I-USERNAME\",\n",
      "    \"7\": \"B-ID_NUM\",\n",
      "    \"8\": \"I-ID_NUM\",\n",
      "    \"9\": \"B-PHONE_NUM\",\n",
      "    \"10\": \"I-PHONE_NUM\",\n",
      "    \"11\": \"B-URL_PERSONAL\",\n",
      "    \"12\": \"I-URL_PERSONAL\",\n",
      "    \"13\": \"B-STREET_ADDRESS\",\n",
      "    \"14\": \"I-STREET_ADDRESS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"B-EMAIL\": 3,\n",
      "    \"B-ID_NUM\": 7,\n",
      "    \"B-NAME_STUDENT\": 1,\n",
      "    \"B-PHONE_NUM\": 9,\n",
      "    \"B-STREET_ADDRESS\": 13,\n",
      "    \"B-URL_PERSONAL\": 11,\n",
      "    \"B-USERNAME\": 5,\n",
      "    \"I-EMAIL\": 4,\n",
      "    \"I-ID_NUM\": 8,\n",
      "    \"I-NAME_STUDENT\": 2,\n",
      "    \"I-PHONE_NUM\": 10,\n",
      "    \"I-STREET_ADDRESS\": 14,\n",
      "    \"I-URL_PERSONAL\": 12,\n",
      "    \"I-USERNAME\": 6,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pll_data_detection/trained_models/exp001/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
      "\n",
      "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at pll_data_detection/trained_models/exp001.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n",
      "Didn't find file pll_data_detection/trained_models/exp001/added_tokens.json. We won't load it.\n",
      "loading file pll_data_detection/trained_models/exp001/vocab.txt\n",
      "loading file pll_data_detection/trained_models/exp001/tokenizer.json\n",
      "loading file None\n",
      "loading file pll_data_detection/trained_models/exp001/special_tokens_map.json\n",
      "loading file pll_data_detection/trained_models/exp001/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_OUTPUT_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classification = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",  # サブワードを集約して元の単語レベルでの予測を得る\n",
    "    ignore_subwords=True,  # サブワードの予測を無視する\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 10, 16, 20, 56, 86, 93, 104, 112, 123]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-NAME_STUDENT',\n",
       "  'score': 0.4579974,\n",
       "  'index': 29,\n",
       "  'word': 'stefano',\n",
       "  'start': 156,\n",
       "  'end': 163},\n",
       " {'entity': 'B-NAME_STUDENT',\n",
       "  'score': 0.3540913462638855,\n",
       "  'index': 30,\n",
       "  'word': 'lovato',\n",
       "  'start': 164,\n",
       "  'end': 170},\n",
       " {'entity': 'I-NAME_STUDENT',\n",
       "  'score': 0.32486668,\n",
       "  'index': 33,\n",
       "  'word': 'md',\n",
       "  'start': 172,\n",
       "  'end': 174}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 10, 16, 20, 56, 86, 93, 104, 112, 123]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[\"document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f31b08172244399c0d33c26eecf6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = []\n",
    "for document_id, full_text, tokens in tqdm(\n",
    "    zip(test_dataset[\"document\"], test_dataset[\"full_text\"], test_dataset[\"tokens\"]),\n",
    "    total=len(test_dataset),\n",
    "):\n",
    "    # 予測の実行\n",
    "    results = token_classification(full_text)\n",
    "    # サブワードを結合\n",
    "    combined_results = combine_subword(results)\n",
    "    # 結合されたサブワードのindexより、元のテキストを取得\n",
    "    org_texts_entities = [\n",
    "        (\n",
    "            full_text[combined_result[\"start\"] : combined_result[\"end\"]],\n",
    "            combined_result[\"entity\"],\n",
    "        )\n",
    "        for combined_result in combined_results\n",
    "    ]\n",
    "    # tokensの中から、org_textsに一致するもののindexを取得\n",
    "    tokens_idx = [(idx, token) for idx, token in enumerate(tokens)]\n",
    "    used_idx = 0\n",
    "    for org_text, entity in org_texts_entities:\n",
    "        for token_idx, token in tokens_idx[used_idx:]:  # 前回のindexより後しか見ない\n",
    "            if token.startswith(org_text):\n",
    "                outputs.append([document_id, token_idx, entity, org_text, token])\n",
    "                used_idx = token_idx\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "output_df = pl.DataFrame(\n",
    "    outputs, schema=[\"document\", \"token\", \"label\", \"org_text\", \"token_text\"]\n",
    ")\n",
    "\n",
    "os.makedirs(SUB_OUTPUT_PATH, exist_ok=True)\n",
    "output_df.select(pl.col([\"document\", \"token\", \"label\"])).with_row_index(\n",
    "    name=\"row_id\"\n",
    ").write_csv(f\"{SUB_OUTPUT_PATH}/sample_sumission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
