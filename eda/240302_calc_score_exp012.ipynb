{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "valid_dfを用いて、以下２つの観点でscoreを計算する\n",
    "- 出力からラベル列を生成する\n",
    "- 存在するデータから計算する\n",
    "\n",
    "詳細\n",
    "- https://www.notion.so/exp011-valid-f5score-e5ae29d2fd704ac799c142b6844a5b16?pvs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_json(\"../data/train.json\")\n",
    "data = pl.read_csv(\"../valid_df/exp012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6807, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全行を表示する\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出力からラベル列を生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = (\n",
    "    data.select(\n",
    "        pl.col(\"document_pred\").replace(\"null\", None).cast(pl.Int64),\n",
    "        pl.col(\"token_pred\").replace(\"null\", None).cast(pl.Int64),\n",
    "        pl.col(\"label_pred\").replace(\"null\", None),\n",
    "    )\n",
    "    .drop_nulls()\n",
    "    .sort(\"document_pred\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_only_valid_document = train.filter(\n",
    "#     pl.col(\"document\").is_in(\n",
    "#         pred_df.get_column(\"document_pred\").unique()\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_only_valid_document = train_only_valid_document.with_columns(\n",
    "#     pl.col(\"tokens\").map_elements(len).alias(\"tokens_len\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_token_len = train.with_columns(\n",
    "    pl.col(\"tokens\").map_elements(len).alias(\"tokens_len\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_agg_with_len = (\n",
    "    pred_df.group_by(\"document_pred\")\n",
    "    .agg(\n",
    "        pl.col(\"token_pred\"),\n",
    "        pl.col(\"label_pred\"),\n",
    "    )\n",
    "    .join(\n",
    "        train_with_token_len.select([\"document\", \"tokens_len\", \"labels\"]),\n",
    "        left_on=\"document_pred\",\n",
    "        right_on=\"document\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論したlabel列を\n",
    "label_pred_alls = []\n",
    "for token_pred, label_pred, tokens_len in zip(\n",
    "    pred_df_agg_with_len[\"token_pred\"],\n",
    "    pred_df_agg_with_len[\"label_pred\"],\n",
    "    pred_df_agg_with_len[\"tokens_len\"],\n",
    "):\n",
    "    label_pred_all = [\"O\" for _ in range(tokens_len)]\n",
    "    for token, label in zip(token_pred, label_pred):\n",
    "        label_pred_all[token] = label\n",
    "    label_pred_alls.append(label_pred_all)\n",
    "\n",
    "actual_pred_df = pred_df_agg_with_len.with_columns(\n",
    "    pl.Series(\"label_pred_all\", label_pred_alls)\n",
    ").select([\"labels\", \"label_pred_all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9074074074074073, 0.9168105929763961)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seqeval.metrics.sequence_labeling import precision_recall_fscore_support\n",
    "\n",
    "calculated_f1_score = precision_recall_fscore_support(\n",
    "    actual_pred_df[\"labels\"].to_list(),\n",
    "    actual_pred_df[\"label_pred_all\"].to_list(),\n",
    "    beta=1,\n",
    "    average=\"micro\",\n",
    ")[2]\n",
    "\n",
    "calculated_f5_score = precision_recall_fscore_support(\n",
    "    actual_pred_df[\"labels\"].to_list(),\n",
    "    actual_pred_df[\"label_pred_all\"].to_list(),\n",
    "    beta=5,\n",
    "    average=\"micro\",\n",
    ")[2]\n",
    "\n",
    "calculated_f1_score, calculated_f5_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinichiro.saito/pll_data_detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         EMAIL       0.86      1.00      0.92         6\n",
      "        ID_NUM       0.94      0.89      0.92        19\n",
      "  NAME_STUDENT       0.91      0.92      0.92       222\n",
      "     PHONE_NUM       0.33      1.00      0.50         1\n",
      "STREET_ADDRESS       0.00      0.00      0.00         1\n",
      "  URL_PERSONAL       0.85      1.00      0.92        17\n",
      "      USERNAME       0.00      0.00      0.00         1\n",
      "\n",
      "     micro avg       0.90      0.92      0.91       267\n",
      "     macro avg       0.56      0.69      0.60       267\n",
      "  weighted avg       0.90      0.92      0.91       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        actual_pred_df[\"labels\"].to_list(),\n",
    "        actual_pred_df[\"label_pred_all\"].to_list(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存在するデータから計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f5_score(precision: float, recall: float, beta: int = 5):\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609728956362769"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_df = data.select(\n",
    "    pl.col([\"document\", \"token\", \"token_str\"]).drop_nulls()\n",
    ").unique()\n",
    "\n",
    "pred_df = data.select(\n",
    "    pl.col([\"document_pred\", \"token_pred\", \"token_str_pred\"]).drop_nulls()\n",
    ").unique()\n",
    "\n",
    "correct_num = actual_df.join(\n",
    "    pred_df,\n",
    "    left_on=[\"document\", \"token\", \"token_str\"],\n",
    "    right_on=[\"document_pred\", \"token_pred\", \"token_str_pred\"],\n",
    "    how=\"inner\",\n",
    ").height\n",
    "\n",
    "actual_but_not_pred_num = actual_df.join(\n",
    "    pred_df,\n",
    "    left_on=[\"document\", \"token\", \"token_str\"],\n",
    "    right_on=[\"document_pred\", \"token_pred\", \"token_str_pred\"],\n",
    "    how=\"anti\",\n",
    ").height\n",
    "\n",
    "pred_but_not_actual_num = pred_df.join(\n",
    "    actual_df,\n",
    "    left_on=[\"document_pred\", \"token_pred\", \"token_str_pred\"],\n",
    "    right_on=[\"document\", \"token\", \"token_str\"],\n",
    "    how=\"anti\",\n",
    ").height\n",
    "\n",
    "precision = correct_num / (correct_num + pred_but_not_actual_num)\n",
    "recall = correct_num / (correct_num + actual_but_not_pred_num)\n",
    "\n",
    "f5_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
